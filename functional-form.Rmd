# Functional Forms and Non-linearity

## Non-linearity

### What's the problem?

If the relationship between the regression surface and $E(Y | X)$ is not captured well, then the results of the regression may be misleading, although this depends on the modeling approach regression is being used for.

The extent of the problem varies with which variables are affected, and the purpose of the analysis.

1. If the analysis is interested in the average marginal effect of the treatment variable, then using the OLS coefficient to estimate the AME is not a bad approximation. The values of the individual marginal effects will be incorrect, but the average should be a reasonable approximation. If you are interested in the AME of sub-populations or other estimands, then you will need to account for the non-linearity.
2. If the non-linearity is in the control variables, then it is another form of omitted variable bias.

### What to do about it? And How to Solve it?

The general approaches to identifying non-linearity include:

- Residual plots with curvature tests: `r rdoc("car", "residualPlots", TRUE)`
- Added-variable (AV) plot: `r rdoc("car", "avPlots", TRUE)`.
- Component+residual (CERES) plot:  `r rdoc("car", "crPlots", TRUE)` and `r rdoc("car", "ceresPlots", TRUE)`.
- Ramsay RESET test.  `r rdoc("lmtest", "resettest", TRUE)`
- Compare Robust SE and classical OLS SE [@KingRoberts2015a].

In general, I think most of these approaches are time consuming, sub-optimal given new methods and computation, and open up the regression model to too many researcher degrees of freedom that will not be represented in the uncertainty of the model

There now exist many models (notably semi-parametric and non-parametric) which allow for more flexible functional forms with less-model dependence. Some of these include:

1. GAM and spline models
2. K-nearest neighbor models
3. Matching methods
4. LASSO, Ridge and other Shrinkage Regression (especially with basis functions)


## Logarithm

### Examples of Relevant Theories

- Converts multiplicative theories to additive theories. Theories with diminishing returns to scale. Theories about percentage changes or growth.
- Most uses of (per capita) GDP, population:
- [Cobb-Douglas production function](https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function)
  $$
  y = \alpha (K^(\delta) L^(1 - \delta))^{\nu}
  $$
  Linearized,
  $$
  \log y = \log \alpha + \log k
  $$
- [Gravity model of trade](https://en.wikipedia.org/wiki/Gravity_model_of_trade)
- [Lanchester laws for casualties](https://en.wikipedia.org/wiki/Lanchester%27s_laws)
  $$
  \Delta x = \alpha x^\beta y^\gamma
  $$
  where $\Delta x$ are casualties per period, $x$ is the initial size of forces forces, and $y$ are opposing forces.
  This can be linearized and estimated with OLS,
  $$
  \log \Delta x = \log \alpha + \beta \log x + \gamma \log y
  $$
  as long as $x, y > 0$ (and preferably large).

## Miscellaneous

### Square Root and Variance Stabalizing Transformations

### Power-Transformation

## Polynomials

### Squared

#### What theories?

- [Kuznets curve](https://en.wikipedia.org/wiki/Kuznets_curve): economic development and inequality
- [Environmental Kuznets curve](https://en.wikipedia.org/wiki/Kuznets_curve): environmental quality and economic development
- Democratic Civil Peace: intermediate regimes prone to civil war, democracies and autocracies are less prone to civil war.

### Higher-Order Polynomials

- Time cubed
- Seat-Vote curves? Other old examples @Tufte1975a.
- These are generally

## Interactions

See @Braumoeller2004a @FranzeseKam2007a, @ClarkGilliganGolder2006a, @BramborClarkGolder2006a, @BerryGolderMilton2012a, and @Goldera for more details on the interpretation of interactions.

### Theories

@BerryGolderMilton2012a recommend that for simple interaction model such as:
$$
\vec{y} = \beta_0 + \beta_x \vec{x} + \beta_z \vec{z} + \beta_{xz} \vec{x} \vec{z} + \vec{\epsilon}
$$
the reseearcher make as many of the following predictions as possible

1. The marginal effect of $X$ is (positive, negative, zero) when $Z$ is at its **lowest** level.
2. ... when $Z$ is at its **highest** level.
3. The marginal effect of $Z$ is (positive, negative, zero) when $X$ is at its lowest level.
4. ... when $X$ is at its **highest** level.
5. The marginal effect of each $X$ and $Z$ is (positively, negatively) related to the other variable

@BerryGolderMilton2012a recommend t

1. Use multiplicative interaction models for conditional hypotheses.
2. Include all constituent terms of the interaction in the model.
3. Do not interpret coefficients on terms seperately, or as if they are unconditional marginal effects.
4. Calculate substantively meaningful marginal effects and their standard errors.

@BerryGolderMilton2012a recommend the following plot

1. Construct marginal effect plots for both $X$ and $Z$.
2. The range of the horizontal axis should extend from the minimum to the maximum value of variable in the sample.
3. The plot should include a frequency distribution of the variable of interest, as either a rug plot, histogram, or density.
4. Report the product term coefficient and its t-statistic or standard error.


## References

- Matt Golder [Interactions](http://mattgolder.com/interactions)
- Golder's papers

## Non-linear functional forms

| model  | Equation | $\beta_1$ interpretation |
|--------|----------|--------------------------|
| Level-level | $Y = \beta_0 + \beta_1 X$ | 1-unit $\Delta X \approx \beta_1 \Delta Y$ |
| log-level | $Y = \beta_0 + \beta_1 X$ | 1-unit $\Delta X \approx \beta_1 \Delta Y$ |
| level-log | $Y = \beta_0 + \beta_1 X$ | 1% $\Delta X \approx (\beta_1 / 100)\Delta Y$ |
| log-log | $Y = \beta_0 + \beta_1 X$ | 1% $\Delta X \approx \beta_1 \%\Delta Y$ |

One of the more useful features of natural logarithms is that log-differences are that approximately percent differences,
$$
\log(x) - \log(y) \approx \frac{x - y}{y} ,
$$
when $(x - y) / y \approx 0$
This approximation works best for small changes.

When $\delta \approx 0$, $\log(1 + \delta) \approx \delta$.
This means that small changes in the log-transformed variables can be interpreted as percentage chanages,
$$
\log(x (1 + \delta)) = \log(x) + \log(1 + \delta) = \log(x) + \delta
$$

The approximation $log(1 + \delta) \approx \delta$ is be derived from the [first-order Taylor exansion](https://en.wikipedia.org/wiki/Taylor_series) of $\log(x)$ near $x = 1$.
$$
\begin{aligned}[t]
\log(x) \approx \log(x_0) + \frac{1}{x_0} (x - x_0) = \log(1) + 1 \times (x - 1) \\ 
= x - 1
\end{aligned}
$$
```{r}
ggplot(gather(tibble(x = seq(0.5, 2, by = 0.01),
              `x - 1` = x - 1,
              `log(x)` = log(x)),
              `f(x)`, y, -x)) +
  geom_line(aes(x = x, y = y, colour = `f(x)`)) +
  geom_hline(yintercept = 0)
```

1. The approximation works best when the change is small
2. The log difference is always an underestimate of the discrete rate of change.

The Taylor expansion appears repeatedly in statistics, when an approximation for an otherwise intractable function is used.
A commom application of Taylor expansion is th 
[Delta rule](https://en.wikipedia.org/wiki/Delta_rule), used to calculate the variance of a function of a random variable.

- [Why is it that natural log changes are percentage changes? What is about logs that makes this so?](http://stats.stackexchange.com/questions/244199/why-is-it-that-natural-log-changes-are-percentage-changes-what-is-about-logs-th)
- Ragnar Nymoen [The natural logarithm](http://www.uio.no/studier/emner/sv/oekonomi/ECON4150/v13/undervisningsmateriale/loglinearnote-.pdf)



## Squared terms

$$
\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i + \hat{\beta}_2 X_i^2
$$
This is like an interaction of $X$ with itself.
The marginal effect of $X_i$ varies as a function of $X_i$,
$$
\frac{\partial \E(Y_i | X_i)}{\partial X_i} = \beta_1 + \beta_2 X_i
$$

Examples of some theories with "squared terms":

- Kuznet's curve
- Environmental Kuznet's curve
- U-shaped relationship between democracy and stability
- U-shaped relationship between democracy and stability

When 

Note that polynomials can be used to arbitrarily approximate [any function](https://en.wikipedia.org/wiki/Approximation_theory) (with some caveats).
So even if the population relationship $\E(Y | X) \neq \beta_1 X^1 + \beta_2 X ^2 + ... $,
a polynomial function can be used to approximate that relationship.

**Caveats:**

- Including higher order polynomials can lead to overfitting.
- Most social science theories are not specified in terms of a specific function that relates $X$ and $Y$, instead only specifying the sign of the relationship, or perhaps a second derivative. Whether that means that we should use simpler (only a linear relationship) or more flexible functional forms in the estimation is still unclear to me and depends on the purpose of the analysis.
