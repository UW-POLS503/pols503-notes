---
title: Discrete Dependent Variables
---

# Discrete Dependent Variables

## Linear Probability Model

When OLS is used with a binary (dichotomous) dependent variable, then it is called a linear probability model (LPM).

The model is the same as OLS,
$$
\vec{y} = \mat{X} \vec{beta} + \varepsilon ,
$$
only the interpretation changes slightly.
Since $y_i$ takes only values of zero or one, $\E(y_i)$ is a probability, and $\beta$ is interpreted as a marginal increase in $x$ is associated with an expected $\beta$ probability increase in $y$.
Note that the units of $\E(y)$ are probability. 
This is different than "percentage" change interpretations with log-transformed variables.

1. Produces expected values outside the range of the outcome variable.
2. Implies non-zero probability of impossible values of the outcome variable.
3. The residusls have a non-constant variance.
3. The residuals are not normally distributed.

Other models for binary or categorical variables, such as logit or probit models, do not (necessarily) have these problems. 

Given these problems and alternatives, why would anyone still use the linear probability model (LPM)?
It depends on the purpose of the analysis.
If the purpose is prediction or description, e.g. you want to know $\E(y_i)$ for a given $\vec{x}$, then LPM is inappropriate.
However, LPM is useful when you are interested using regression for causal inference. 
Even though the estimates of $\beta$ and individual expected values for observations are poor in the LPM, it provides relatively good estimates of the average marginal effect.
See [Probit better than LPM?](http://www.mostlyharmlesseconometrics.com/2012/07/probit-better-than-lpm/).


## Binomial Generalized Linear Model

- Logit
- Probit



