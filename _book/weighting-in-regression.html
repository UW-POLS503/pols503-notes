<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>POLS 503: Advanced Quantitative Political Methodology: The Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>">
  <meta name="generator" content="bookdown 0.0.71 and GitBook 2.6.7">

  <meta property="og:title" content="POLS 503: Advanced Quantitative Political Methodology: The Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>" />
  <meta name="github-repo" content="UW-POLS503/pols503-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="POLS 503: Advanced Quantitative Political Methodology: The Notes" />
  
  <meta name="twitter:description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>" />
  

<meta name="author" content="Jeffrey B. Arnold">

<meta name="date" content="2016-05-25">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="non-constant-variances-and-correlated-errors.html">
<link rel="next" href="interpreting-regression-coefficients.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>

$$
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

\newcommand{\distr}[1]{\mathcal{#1}}
\newcommand{\dnorm}{\distr{N}}
\newcommand{\dmvnorm}[1]{\distr{N}_{#1}}
$$

  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><i class="fa fa-check"></i><b>2</b> Linear Regression and the Ordinary Least Squares (OLS) Estimator</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#linear-regression-function"><i class="fa fa-check"></i><b>2.1</b> Linear Regression Function</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#ordinary-least-squares"><i class="fa fa-check"></i><b>2.2</b> Ordinary Least Squares</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#properties-of-the-ols-estimator"><i class="fa fa-check"></i><b>2.3</b> Properties of the OLS Estimator</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#what-makes-an-estimator-good"><i class="fa fa-check"></i><b>2.3.1</b> What makes an estimator good?</a></li>
<li class="chapter" data-level="2.3.2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#properties-of-ols"><i class="fa fa-check"></i><b>2.3.2</b> Properties of OLS</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#references"><i class="fa fa-check"></i><b>2.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ols-inference.html"><a href="ols-inference.html"><i class="fa fa-check"></i><b>3</b> OLS Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="ols-inference.html"><a href="ols-inference.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1</b> Sampling Distribution</a></li>
<li class="chapter" data-level="3.2" data-path="ols-inference.html"><a href="ols-inference.html#t-tests-for-single-parameters"><i class="fa fa-check"></i><b>3.2</b> t-tests for single parameters</a></li>
<li class="chapter" data-level="3.3" data-path="ols-inference.html"><a href="ols-inference.html#f-tests-of-multiple-hypotheses"><i class="fa fa-check"></i><b>3.3</b> F-tests of Multiple Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html"><i class="fa fa-check"></i><b>4</b> Omitted Variable Bias and Measurement Error</a><ul>
<li class="chapter" data-level="4.1" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#omitted-variable-bias"><i class="fa fa-check"></i><b>4.1</b> Omitted Variable Bias</a><ul>
<li class="chapter" data-level="4.1.1" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#whats-the-problem"><i class="fa fa-check"></i><b>4.1.1</b> What’s the problem?</a></li>
<li class="chapter" data-level="4.1.2" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#what-to-do-about-it"><i class="fa fa-check"></i><b>4.1.2</b> What to do about it?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#measurement-error"><i class="fa fa-check"></i><b>4.2</b> Measurement Error</a><ul>
<li class="chapter" data-level="4.2.1" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#whats-the-problem-1"><i class="fa fa-check"></i><b>4.2.1</b> What’s the problem?</a></li>
<li class="chapter" data-level="4.2.2" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#what-to-do-about-it-1"><i class="fa fa-check"></i><b>4.2.2</b> What to do about it?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html"><i class="fa fa-check"></i><b>5</b> Collinearity and Multicollinearity</a><ul>
<li class="chapter" data-level="5.1" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#perfect-collinearity"><i class="fa fa-check"></i><b>5.1</b> (Perfect) Collinearity</a></li>
<li class="chapter" data-level="5.2" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#multicollinearity"><i class="fa fa-check"></i><b>5.2</b> Multicollinearity</a><ul>
<li class="chapter" data-level="5.2.1" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#what-to-do-about-it-3"><i class="fa fa-check"></i><b>5.2.1</b> What to do about it?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html"><i class="fa fa-check"></i><b>6</b> Functional Form and Non-linearity</a><ul>
<li class="chapter" data-level="6.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#non-linearity"><i class="fa fa-check"></i><b>6.1</b> Non-linearity</a><ul>
<li class="chapter" data-level="6.1.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#whats-the-problem-2"><i class="fa fa-check"></i><b>6.1.1</b> What’s the problem?</a></li>
<li class="chapter" data-level="6.1.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#what-to-do-about-it-and-how-to-solve-it"><i class="fa fa-check"></i><b>6.1.2</b> What to do about it? And How to Solve it?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#logarithm"><i class="fa fa-check"></i><b>6.2</b> Logarithm</a><ul>
<li class="chapter" data-level="6.2.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#examples-of-relevant-theories"><i class="fa fa-check"></i><b>6.2.1</b> Examples of Relevant Theories</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#miscellaneous"><i class="fa fa-check"></i><b>6.3</b> Miscellaneous</a><ul>
<li class="chapter" data-level="6.3.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#square-root-and-variance-stabalizing-transformations"><i class="fa fa-check"></i><b>6.3.1</b> Square Root and Variance Stabalizing Transformations</a></li>
<li class="chapter" data-level="6.3.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#power-transformation"><i class="fa fa-check"></i><b>6.3.2</b> Power-Transformation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#polynomials"><i class="fa fa-check"></i><b>6.4</b> Polynomials</a><ul>
<li class="chapter" data-level="6.4.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#squared"><i class="fa fa-check"></i><b>6.4.1</b> Squared</a></li>
<li class="chapter" data-level="6.4.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#higher-order-polynomials"><i class="fa fa-check"></i><b>6.4.2</b> Higher-Order Polynomials</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#interactions"><i class="fa fa-check"></i><b>6.5</b> Interactions</a><ul>
<li class="chapter" data-level="6.5.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#theories"><i class="fa fa-check"></i><b>6.5.1</b> Theories</a></li>
<li class="chapter" data-level="6.5.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#recommendations"><i class="fa fa-check"></i><b>6.5.2</b> Recommendations</a></li>
<li class="chapter" data-level="6.5.3" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#plots"><i class="fa fa-check"></i><b>6.5.3</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#flexible-functional-forms"><i class="fa fa-check"></i><b>6.6</b> Flexible Functional Forms</a></li>
<li class="chapter" data-level="6.7" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#references-1"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html"><i class="fa fa-check"></i><b>7</b> Non-constant Variances and Correlated Errors</a><ul>
<li class="chapter" data-level="7.1" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#iid-errors"><i class="fa fa-check"></i><b>7.1</b> iid errors</a></li>
<li class="chapter" data-level="7.2" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#heteroskedasticity"><i class="fa fa-check"></i><b>7.2</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.2.1" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#diagnostics"><i class="fa fa-check"></i><b>7.2.1</b> Diagnostics</a></li>
<li class="chapter" data-level="7.2.2" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#dealing-with-heteroskedasticity"><i class="fa fa-check"></i><b>7.2.2</b> Dealing with Heteroskedasticity</a></li>
<li class="chapter" data-level="7.2.3" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#advice"><i class="fa fa-check"></i><b>7.2.3</b> Advice</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#clustered-errors"><i class="fa fa-check"></i><b>7.3</b> Clustered Errors</a></li>
<li class="chapter" data-level="7.4" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#serial-correlation"><i class="fa fa-check"></i><b>7.4</b> Serial Correlation</a></li>
<li class="chapter" data-level="7.5" data-path="non-constant-variances-and-correlated-errors.html"><a href="non-constant-variances-and-correlated-errors.html#non-normal-errors"><i class="fa fa-check"></i><b>7.5</b> Non-Normal Errors</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html"><i class="fa fa-check"></i><b>8</b> Weighting in Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html#weighted-least-squares-wls"><i class="fa fa-check"></i><b>8.1</b> Weighted Least Squares (WLS)</a></li>
<li class="chapter" data-level="8.2" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html#when-should-you-use-wls"><i class="fa fa-check"></i><b>8.2</b> When should you use WLS?</a><ul>
<li class="chapter" data-level="8.2.1" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html#correcting-for-known-heteroskedasticity"><i class="fa fa-check"></i><b>8.2.1</b> Correcting for Known Heteroskedasticity</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html#references-2"><i class="fa fa-check"></i><b>8.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html"><i class="fa fa-check"></i><b>9</b> Interpreting Regression Coefficients</a><ul>
<li class="chapter" data-level="9.1" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#interpreting-coefficients"><i class="fa fa-check"></i><b>9.1</b> Interpreting Coefficients</a></li>
<li class="chapter" data-level="9.2" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#finite-differences-and-marginal-effects"><i class="fa fa-check"></i><b>9.2</b> Finite Differences and Marginal Effects</a></li>
<li class="chapter" data-level="9.3" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#standardized-coefficients"><i class="fa fa-check"></i><b>9.3</b> Standardized Coefficients</a></li>
<li class="chapter" data-level="9.4" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#marginal-effects-and-first-difference"><i class="fa fa-check"></i><b>9.4</b> Marginal Effects and First Difference</a></li>
<li class="chapter" data-level="9.5" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#references-3"><i class="fa fa-check"></i><b>9.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression-diagnostics.html"><a href="regression-diagnostics.html"><i class="fa fa-check"></i><b>10</b> Regression Diagnostics</a></li>
<li class="chapter" data-level="11" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>11</b> Resampling Methods</a><ul>
<li class="chapter" data-level="11.1" data-path="resampling-methods.html"><a href="resampling-methods.html#bootstrap"><i class="fa fa-check"></i><b>11.1</b> Bootstrap</a></li>
<li class="chapter" data-level="11.2" data-path="resampling-methods.html"><a href="resampling-methods.html#cross-validation"><i class="fa fa-check"></i><b>11.2</b> Cross-Validation</a><ul>
<li class="chapter" data-level="11.2.1" data-path="resampling-methods.html"><a href="resampling-methods.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>11.2.1</b> Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="11.2.2" data-path="resampling-methods.html"><a href="resampling-methods.html#cross-validation-1"><i class="fa fa-check"></i><b>11.2.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="11.2.3" data-path="resampling-methods.html"><a href="resampling-methods.html#other-quantities"><i class="fa fa-check"></i><b>11.2.3</b> Other Quantities</a></li>
<li class="chapter" data-level="11.2.4" data-path="resampling-methods.html"><a href="resampling-methods.html#others"><i class="fa fa-check"></i><b>11.2.4</b> Others</a></li>
<li class="chapter" data-level="11.2.5" data-path="resampling-methods.html"><a href="resampling-methods.html#references-4"><i class="fa fa-check"></i><b>11.2.5</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html"><i class="fa fa-check"></i><b>12</b> Panel (Longitudinal) Data</a><ul>
<li class="chapter" data-level="12.1" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#terminology"><i class="fa fa-check"></i><b>12.1</b> Terminology</a></li>
<li class="chapter" data-level="12.2" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#fixed-effects"><i class="fa fa-check"></i><b>12.2</b> Fixed Effects</a><ul>
<li class="chapter" data-level="12.2.1" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#estimating"><i class="fa fa-check"></i><b>12.2.1</b> Estimating</a></li>
<li class="chapter" data-level="12.2.2" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#causal-inference"><i class="fa fa-check"></i><b>12.2.2</b> Causal Inference</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#lagged-dependent-variables"><i class="fa fa-check"></i><b>12.3</b> Lagged Dependent Variables</a></li>
<li class="chapter" data-level="12.4" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#random-effects"><i class="fa fa-check"></i><b>12.4</b> Random Effects</a><ul>
<li class="chapter" data-level="12.4.1" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#how-to-estimate-random-effects"><i class="fa fa-check"></i><b>12.4.1</b> How to estimate random effects?</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#difference-in-difference-estimators"><i class="fa fa-check"></i><b>12.5</b> Difference in Difference Estimators</a></li>
<li class="chapter" data-level="12.6" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#non-standard-error-issues"><i class="fa fa-check"></i><b>12.6</b> Non-standard Error Issues</a></li>
<li class="chapter" data-level="12.7" data-path="panel-longitudinal-data.html"><a href="panel-longitudinal-data.html#references-5"><i class="fa fa-check"></i><b>12.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>13</b> Appendix</a><ul>
<li class="chapter" data-level="13.1" data-path="appendix.html"><a href="appendix.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>13.1</b> Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="references-6.html"><a href="references-6.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">POLS 503: Advanced Quantitative Political Methodology: The Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="weighting-in-regression" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Weighting in Regression</h1>
<div id="weighted-least-squares-wls" class="section level2">
<h2><span class="header-section-number">8.1</span> Weighted Least Squares (WLS)</h2>
<p>Ordinary least squares estimates coefficients by finding the coefficients that minimize the sum of squared errors, <span class="math display">\[
\hat{\beta}_{OLS} = \argmin_{\vec{b}} \sum_{i = 1}^N (y_i - \vec{x}\T \vec{b})^2 .
\]</span> In the objective function, it treats the errors of all observations equally. However, there may be situations where we are more concerned about minimizing some errors more than others. For example, suppose we know that some <span class="math inline">\(y_i\)</span> have more measurement error than others, then we may care more about minimizing errors for those <span class="math inline">\(y_i\)</span> which we are more certain about.</p>
<p>In weighted least squares (WLS) we estimate the coefficients by finding the values that minimize the <em>weighted</em> sum of squared errors, <span class="math display">\[
\hat{\beta}_{WLS} = \argmin_{\vec{b}} \sum_{i = 1}^N w_i (y_i - \vec{x}\T \vec{b})^2 ,
\]</span> where <span class="math inline">\(w_i\)</span> are the weights for each observation. Note that OLS is a special case of WLS where <span class="math inline">\(w_i = 1\)</span> for all the observations.</p>
</div>
<div id="when-should-you-use-wls" class="section level2">
<h2><span class="header-section-number">8.2</span> When should you use WLS?</h2>
<p>The previous section showed what WLS is, but when should you use weighted regression?</p>
<p>Suppose we have weights for observations, when should we use them? Well, it depends on the purpose of your analysis:</p>
<ol style="list-style-type: decimal">
<li>If you are estimating population descriptive statistics, then weighting is needed to ensure that the sample is representative of the population.</li>
<li>If you are concerned with causal inference, then weighting is more nuanced. You may or may not need to weight, and it will often be unclear which is better.</li>
</ol>
<p>There are three reasons for weighting in causal inference <span class="citation">(Solon, Haider, and Wooldridge <a href="#ref-SolonHaiderWooldridge2015a">2015</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li>Correct standard errors for heteroskedasticity</li>
<li>Get consistent estimates by correcting for endogenous sampling</li>
<li>Identify average partial effects when there is unmodeled heterogeneity in the effects.</li>
</ol>
<p><em>Heteroskedasticity:</em> Estimate OLS and WLS. If the model is misspecified or there is endogenous selection, then OLS and WLS have different probability limits. The constrast between OLS and WLS estimatates is a diagnostic for model misspecification or endogenous sampling. Always use robust standard errors.</p>
<p><em>Endogenous sampling:</em> If the sample weights vary exogenously instead of endogenously, then weighting may be harmful for precision. The OLS still specifies the conditional mean. Sampling is exogenous if the sampling probabilities are independent of the error - e.g. if they are only functions of the explanatory variables. If the probabilities are a function of the dependent variable, then they are endogenous. (1) if sampling rate is endogenous, weight by inverse selection. (2) use robust standard errors. (3) if sampling rate is exogenous, then OLS and WLS are consistent. Use OLS and WLS as test of model mispecification.</p>
<p><em>Heterogeneous effects:</em> Identifying average partial effects. WLS estimates the linear regression of the population, but this is not the same as the average partial effects. But that is because OLS does not estimate the average partial effect, but weights according to the variance in X.</p>
<div id="correcting-for-known-heteroskedasticity" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Correcting for Known Heteroskedasticity</h3>
<p>When are there cases with known heteroskedasticity? This is probably rare, but it arises in a few circumstances:</p>
<ol style="list-style-type: decimal">
<li>The outcome variable consists of measurements with a given measurement error. For example, the <span class="math inline">\(y\)</span> come from instruments or are estimated themselves.</li>
<li>The error of output depends on input variables in known ways. For example, the sampling error of polls.</li>
</ol>
<p>Suppose that the heteroskedasticity is known up to a multiplicative constant, <span class="math display">\[
\Var(\varepsilon_i | \mat{X}) = a_i \sigma^2 ,
\]</span> where <span class="math inline">\(a_i = a_i \vec{x}_i&#39;\)</span> is a positive and known function of <span class="math inline">\(\vec{x}_i\)</span>.</p>
<p>Then in weighted least squares multiply <span class="math inline">\(y_i\)</span> by <span class="math inline">\(1 / \sqrt{a_i}\)</span>, <span class="math display">\[
\begin{aligned}[t]
y_i &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_K x_K + \varepsilon_i \\
y_i / \sqrt{a_i} &amp;= \beta_0 / \sqrt{a_i} + \beta_1 x_1 / \sqrt{a_1} + \beta_2 x_2 / \sqrt{a_2} + \dots + \beta_K x_K / \sqrt{a_K} + \varepsilon_i^*
\end{aligned}
\]</span> where <span class="math inline">\(\varepsilon_i^* \sim N(0, \sigma^2)\)</span>. This rescales errors to <span class="math inline">\(\varepsilon_i / \sqrt{a_i}\)</span> which keeps <span class="math inline">\(\E(\varepsilon_i) = 0\)</span>, but makes the variance constant, <span class="math display">\[
\Var\left( \frac{1}{\sqrt{a_i}} \varepsilon_i | \mat{X} \right) = \frac{1}{a_i} \Var(\varepsilon_i | \mat{X}) = \frac{1}{a_i} a_i \sigma^2 = \sigma^2
\]</span> If <span class="math inline">\(a_i\)</span> is known, then the model is homoskedastic and the estimator is BLUE.</p>
<p>Define the weighting matrix, <span class="math display">\[
\mat{W} =
\begin{bmatrix}
1 / \sqrt{a_1} &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 / \sqrt{a_2} &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; 0 \\
0 &amp; 0 &amp; \cdots &amp; 1 / \sqrt{a_N}
\end{bmatrix} .
\]</span> Then run the regression, <span class="math display">\[
\begin{aligned}[t]
\mat{W} y &amp;= \mat{W} \mat{X} \vec{\beta} + \mat{W} \vec\varepsilon \\
\vec{y}^* &amp;= \mat{X}^* \vec{\beta} + \vec{\varepsilon}^* .
\end{aligned}
\]</span> Run the regression of <span class="math inline">\(\vec{y}^*\)</span> on <span class="math inline">\(\mat{X}^*\)</span>, and the Gauss-Markov assumptions are satisfied. Then using the usual OLS formula, <span class="math display">\[
\hat{\vec\beta}_{WLS} = ((\mat{X}^*)&#39; \mat{X}^*) (\mat{X}^*)&#39; \vec{y}^* = (\mat{X}&#39; \mat{W}&#39; \mat{W} \mat{X})^{-1} \mat{X}&#39; \mat{W}&#39; \mat{W} \vec{y} .
\]</span></p>
<p><strong>In R</strong> Use <code>lm()</code> with the <code>weights</code> argument.</p>
</div>
</div>
<div id="references-2" class="section level2">
<h2><span class="header-section-number">8.3</span> References</h2>
<ul>
<li>WLS derivation <span class="citation">Fox (<a href="#ref-Fox2016a">2016</a>)</span> 304–306</li>
</ul>
<p>Textbook discussions: <span class="citation">Angrist and Pischke (<a href="#ref-AngristPischke2009">2009</a>)</span> 91–94, <span class="citation">Angrist and Pischke (<a href="#ref-AngristPischke2014">2014</a>)</span> 202–203,</p>
<p><span class="citation">Solon, Haider, and Wooldridge (<a href="#ref-SolonHaiderWooldridge2015a">2015</a>)</span> is a good (and recent) overview with practical advice of when to weight and when not-to weight linear regressions.</p>
<p><span class="citation">Gelman (<a href="#ref-Gelman2007a">2007</a><a href="#ref-Gelman2007a">b</a>)</span>, in the context of post-stratification, proposes controlling for variables related to selection into the sample instead of using survey weights; also see the responses <span class="citation">(Bell and Cohen <a href="#ref-BellCohen2007a">2007</a>; Breidt and Opsomer <a href="#ref-BreidtOpsomer2007a">2007</a>; Little <a href="#ref-Little2007a">2007</a>; Pfeffermann <a href="#ref-Pfeffermann2007a">2007</a>)</span>, and rejoinder <span class="citation">(Gelman <a href="#ref-Gelman2007b">2007</a><a href="#ref-Gelman2007b">a</a>)</span> and <a href="http://andrewgelman.com/2015/07/14/survey-weighting-and-regression-modeling/">blog post</a>. Gelman’s approach is similar to that earlier suggested by <span class="citation">Winship and Radbill (<a href="#ref-WinshipRadbill1994a">1994</a>)</span>.</p>
<p>See also <span class="citation">Deaton (<a href="#ref-Deaton1997a">1997</a>)</span>, <span class="citation">Dumouchel and Duncan (<a href="#ref-DumouchelDuncan1983a">1983</a>)</span>, and <span class="citation">Wissoker (n.d.)</span>.</p>
<p>For survey weighting, see the R package <a href="https://cran.r-project.org/web/packages/survey/survey.pdf">survey</a> and its</p>

</div>
</div>
<h3><span class="header-section-number">14</span> References</h3>
<div id="refs" class="references">
<div id="ref-SolonHaiderWooldridge2015a">
<p>Solon, Gary, Steven J. Haider, and Jeffrey M. Wooldridge. 2015. “What Are We Weighting for?” <em>Journal of Human Resources</em> 61 (2). [Wiley, International Statistical Institute (ISI)]: 317–37. <a href="http://www.jstor.org/stable/1403631" class="uri">http://www.jstor.org/stable/1403631</a>.</p>
</div>
<div id="ref-Fox2016a">
<p>Fox, John. 2016. <em>Applied Regression Analysis &amp; Generalized Linear Models</em>. 3rd ed. Sage.</p>
</div>
<div id="ref-AngristPischke2009">
<p>Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Pr.</p>
</div>
<div id="ref-AngristPischke2014">
<p>Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Pr.</p> 2014. <em>Mastering ’Metrics</em>. Princeton UP.</p>
</div>
<div id="ref-Gelman2007a">
<p>Gelman, Andrew. 2007b. “Struggles with Survey Weighting and Regression Modeling.” <em>Statist. Sci.</em> 22 (2). The Institute of Mathematical Statistics: 153–64. doi:<a href="https://doi.org/10.1214/088342306000000691">10.1214/088342306000000691</a>.</p>
</div>
<div id="ref-BellCohen2007a">
<p>Bell, Robert M., and Michael L. Cohen. 2007. “Comment: Struggles with Survey Weighting and Regression Modeling.” <em>Statist. Sci.</em> 22 (2). The Institute of Mathematical Statistics: 165–67. doi:<a href="https://doi.org/10.1214/088342307000000177">10.1214/088342307000000177</a>.</p>
</div>
<div id="ref-BreidtOpsomer2007a">
<p>Breidt, F. Jay, and Jean D. Opsomer. 2007. “Comment: Struggles with Survey Weighting and Regression Modeling.” <em>Statist. Sci.</em> 22 (2). The Institute of Mathematical Statistics: 168–70. doi:<a href="https://doi.org/10.1214/088342307000000195">10.1214/088342307000000195</a>.</p>
</div>
<div id="ref-Little2007a">
<p>Little, Roderick J. 2007. “Comment: Struggles with Survey Weighting and Regression Modeling.” <em>Statist. Sci.</em> 22 (2). The Institute of Mathematical Statistics: 171–74. doi:<a href="https://doi.org/10.1214/088342307000000186">10.1214/088342307000000186</a>.</p>
</div>
<div id="ref-Pfeffermann2007a">
<p>Pfeffermann, Danny. 2007. “Comment: Struggles with Survey Weighting and Regression Modeling.” <em>Statist. Sci.</em> 22 (2). The Institute of Mathematical Statistics: 179–83. doi:<a href="https://doi.org/10.1214/088342307000000168">10.1214/088342307000000168</a>.</p>
</div>
<div id="ref-Gelman2007b">
<p>Gelman, Andrew. 2007a. “Rejoinder: Struggles with Survey Weighting and Regression Modeling.” <em>Statist. Sci.</em> 22 (2). The Institute of Mathematical Statistics: 184–88. doi:<a href="https://doi.org/10.1214/088342307000000203">10.1214/088342307000000203</a>.</p>
</div>
<div id="ref-WinshipRadbill1994a">
<p>Winship, Christopher, and Larry Radbill. 1994. “Sampling Weights and Regression Analysis.” <em>Sociological Methods &amp; Research</em> 23 (2): 230–57. doi:<a href="https://doi.org/10.1177/0049124194023002004">10.1177/0049124194023002004</a>.</p>
</div>
<div id="ref-Deaton1997a">
<p>Deaton, Angus. 1997. <em>The Analysis of Household Surveys : A Microeconometric Approach to Development Policy</em>. The World Bank. <a href="http://documents.worldbank.org/curated/en/1997/07/694690/analysis-household-surveys-microeconometric-approach-development-policy" class="uri">http://documents.worldbank.org/curated/en/1997/07/694690/analysis-household-surveys-microeconometric-approach-development-policy</a>.</p>
</div>
<div id="ref-DumouchelDuncan1983a">
<p>Dumouchel, William H., and Greg J. Duncan. 1983. “Using Sample Survey Weights in Multiple Regression Analyses of Stratified Samples.” <em>Journal of the American Statistical Association</em> 78 (383): 535–43. doi:<a href="https://doi.org/10.1080/01621459.1983.10478006">10.1080/01621459.1983.10478006</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="non-constant-variances-and-correlated-errors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interpreting-regression-coefficients.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/UW-POLS503/pols503-notes/edit/gh-pages/weighting.Rmd",
"text": "Edit"
},
"download": ["pols503-notes.pdf", "pols503-notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
