<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>POLS 503: Advanced Quantitative Political Methodology: The Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>">
  <meta name="generator" content="bookdown 0.0.60 and GitBook 2.6.7">

  <meta property="og:title" content="POLS 503: Advanced Quantitative Political Methodology: The Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>" />
  <meta name="github-repo" content="UW-POLS503/pols503-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="POLS 503: Advanced Quantitative Political Methodology: The Notes" />
  
  <meta name="twitter:description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>" />
  

<meta name="author" content="Jeffrey B. Arnold">

<meta name="date" content="2016-05-18">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html">
<link rel="next" href="omitted-variable-bias-and-measurement-error.html">

<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>

$$
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

\newcommand{\distr}[1]{\mathcal{#1}}
\newcommand{\dnorm}{\distr{N}}
\newcommand{\dmvnorm}[1]{\distr{N}_{#1}}
$$

  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><i class="fa fa-check"></i><b>2</b> Linear Regression and the Ordinary Least Squares (OLS) Estimator</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#linear-regression-function"><i class="fa fa-check"></i><b>2.1</b> Linear Regression Function</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#ordinary-least-squares"><i class="fa fa-check"></i><b>2.2</b> Ordinary Least Squares</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#properties-of-the-ols-estimator"><i class="fa fa-check"></i><b>2.3</b> Properties of the OLS Estimator</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#what-makes-an-estimator-good"><i class="fa fa-check"></i><b>2.3.1</b> What makes an estimator good?</a></li>
<li class="chapter" data-level="2.3.2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#properties-of-ols"><i class="fa fa-check"></i><b>2.3.2</b> Properties of OLS</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#multi-collinearity"><i class="fa fa-check"></i><b>2.4</b> Multi-Collinearity</a><ul>
<li class="chapter" data-level="2.4.1" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#perfect-collinearity"><i class="fa fa-check"></i><b>2.4.1</b> Perfect Collinearity</a></li>
<li class="chapter" data-level="2.4.2" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#less-than-perfect-collinearity"><i class="fa fa-check"></i><b>2.4.2</b> Less-than Perfect Collinearity</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#weighted-least-squares"><i class="fa fa-check"></i><b>2.5</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-and-the-ordinary-least-squares-ols-estimator.html"><a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html#references"><i class="fa fa-check"></i><b>2.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html"><i class="fa fa-check"></i><b>3</b> Properties of the OLS Estimator</a><ul>
<li class="chapter" data-level="3.1" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html#what-makes-an-estimator-good-1"><i class="fa fa-check"></i><b>3.1</b> What makes an estimator good?</a><ul>
<li class="chapter" data-level="3.1.1" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html#properties-of-ols-1"><i class="fa fa-check"></i><b>3.1.1</b> Properties of OLS</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html#references-1"><i class="fa fa-check"></i><b>3.2</b> References</a></li>
<li class="chapter" data-level="3.3" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html#sampling-distribution-of-ols-coefficients"><i class="fa fa-check"></i><b>3.3</b> Sampling Distribution of OLS Coefficients</a></li>
<li class="chapter" data-level="3.4" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html#t-tests-for-single-parameters"><i class="fa fa-check"></i><b>3.4</b> t-tests for single parameters</a></li>
<li class="chapter" data-level="3.5" data-path="properties-of-the-ols-estimator-1.html"><a href="properties-of-the-ols-estimator-1.html#f-tests-of-multiple-hypotheses"><i class="fa fa-check"></i><b>3.5</b> F-tests of Multiple Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html"><i class="fa fa-check"></i><b>4</b> Omitted Variable Bias and Measurement Error</a><ul>
<li class="chapter" data-level="4.1" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#omitted-variable-bias"><i class="fa fa-check"></i><b>4.1</b> Omitted Variable Bias</a><ul>
<li class="chapter" data-level="4.1.1" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#whats-the-problem"><i class="fa fa-check"></i><b>4.1.1</b> What’s the problem?</a></li>
<li class="chapter" data-level="4.1.2" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#what-to-do-about-it-1"><i class="fa fa-check"></i><b>4.1.2</b> What to do about it?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#measurement-error"><i class="fa fa-check"></i><b>4.2</b> Measurement Error</a><ul>
<li class="chapter" data-level="4.2.1" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#whats-the-problem-1"><i class="fa fa-check"></i><b>4.2.1</b> What’s the problem?</a></li>
<li class="chapter" data-level="4.2.2" data-path="omitted-variable-bias-and-measurement-error.html"><a href="omitted-variable-bias-and-measurement-error.html#what-to-do-about-it-2"><i class="fa fa-check"></i><b>4.2.2</b> What to do about it?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multi-collinearity-1.html"><a href="multi-collinearity-1.html"><i class="fa fa-check"></i><b>5</b> Multi-Collinearity</a><ul>
<li class="chapter" data-level="5.0.1" data-path="multi-collinearity-1.html"><a href="multi-collinearity-1.html#perfect-collinearity-1"><i class="fa fa-check"></i><b>5.0.1</b> Perfect Collinearity</a></li>
<li class="chapter" data-level="5.0.2" data-path="multi-collinearity-1.html"><a href="multi-collinearity-1.html#less-than-perfect-collinearity-1"><i class="fa fa-check"></i><b>5.0.2</b> Less-than Perfect Collinearity</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html"><i class="fa fa-check"></i><b>6</b> Functional Form and Non-linearity</a><ul>
<li class="chapter" data-level="6.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#non-linearity"><i class="fa fa-check"></i><b>6.1</b> Non-linearity</a><ul>
<li class="chapter" data-level="6.1.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#whats-the-problem-2"><i class="fa fa-check"></i><b>6.1.1</b> What’s the problem?</a></li>
<li class="chapter" data-level="6.1.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#what-to-do-about-it-and-how-to-solve-it"><i class="fa fa-check"></i><b>6.1.2</b> What to do about it? And How to Solve it?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#logarithm"><i class="fa fa-check"></i><b>6.2</b> Logarithm</a><ul>
<li class="chapter" data-level="6.2.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#examples-of-relevant-theories"><i class="fa fa-check"></i><b>6.2.1</b> Examples of Relevant Theories</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#miscellaneous"><i class="fa fa-check"></i><b>6.3</b> Miscellaneous</a><ul>
<li class="chapter" data-level="6.3.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#square-root-and-variance-stabalizing-transformations"><i class="fa fa-check"></i><b>6.3.1</b> Square Root and Variance Stabalizing Transformations</a></li>
<li class="chapter" data-level="6.3.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#power-transformation"><i class="fa fa-check"></i><b>6.3.2</b> Power-Transformation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#polynomials"><i class="fa fa-check"></i><b>6.4</b> Polynomials</a><ul>
<li class="chapter" data-level="6.4.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#squared"><i class="fa fa-check"></i><b>6.4.1</b> Squared</a></li>
<li class="chapter" data-level="6.4.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#higher-order-polynomials"><i class="fa fa-check"></i><b>6.4.2</b> Higher-Order Polynomials</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#interactions"><i class="fa fa-check"></i><b>6.5</b> Interactions</a><ul>
<li class="chapter" data-level="6.5.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#theories"><i class="fa fa-check"></i><b>6.5.1</b> Theories</a></li>
<li class="chapter" data-level="6.5.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#recommendations"><i class="fa fa-check"></i><b>6.5.2</b> Recommendations</a></li>
<li class="chapter" data-level="6.5.3" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#plots"><i class="fa fa-check"></i><b>6.5.3</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#flexible-functional-forms"><i class="fa fa-check"></i><b>6.6</b> Flexible Functional Forms</a></li>
<li class="chapter" data-level="6.7" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#references-2"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
<li class="chapter" data-level="6.8" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#non-constant-variances-and-correlated-errors"><i class="fa fa-check"></i><b>6.8</b> Non-constant Variances and Correlated Errors</a><ul>
<li class="chapter" data-level="6.8.1" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#heteroskedasticity"><i class="fa fa-check"></i><b>6.8.1</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="6.8.2" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#heteroskedasticity-1"><i class="fa fa-check"></i><b>6.8.2</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="6.8.3" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#diagnostics"><i class="fa fa-check"></i><b>6.8.3</b> Diagnostics</a></li>
<li class="chapter" data-level="6.8.4" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#dealing-with-heteroskedasticity"><i class="fa fa-check"></i><b>6.8.4</b> Dealing with Heteroskedasticity</a></li>
<li class="chapter" data-level="6.8.5" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#clustering"><i class="fa fa-check"></i><b>6.8.5</b> Clustering</a></li>
<li class="chapter" data-level="6.8.6" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#auto-correlation"><i class="fa fa-check"></i><b>6.8.6</b> Auto-correlation</a></li>
<li class="chapter" data-level="6.8.7" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#clustered-and-panel-standard-errors"><i class="fa fa-check"></i><b>6.8.7</b> Clustered and Panel Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="functional-form-and-non-linearity.html"><a href="functional-form-and-non-linearity.html#non-normal-errors"><i class="fa fa-check"></i><b>6.9</b> Non-Normal Errors</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html"><i class="fa fa-check"></i><b>7</b> Weighting in Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="weighting-in-regression.html"><a href="weighting-in-regression.html#references-3"><i class="fa fa-check"></i><b>7.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html"><i class="fa fa-check"></i><b>8</b> Interpreting Regression Coefficients</a><ul>
<li class="chapter" data-level="8.1" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#standardized-coefficients"><i class="fa fa-check"></i><b>8.1</b> Standardized Coefficients</a></li>
<li class="chapter" data-level="8.2" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#marginal-effects-and-first-difference"><i class="fa fa-check"></i><b>8.2</b> Marginal Effects and First Difference</a></li>
<li class="chapter" data-level="8.3" data-path="interpreting-regression-coefficients.html"><a href="interpreting-regression-coefficients.html#references-4"><i class="fa fa-check"></i><b>8.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="non-standard-errors.html"><a href="non-standard-errors.html"><i class="fa fa-check"></i><b>9</b> Non-standard errors</a><ul>
<li class="chapter" data-level="9.1" data-path="non-standard-errors.html"><a href="non-standard-errors.html#references-5"><i class="fa fa-check"></i><b>9.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>10</b> Resampling Methods</a><ul>
<li class="chapter" data-level="10.1" data-path="resampling-methods.html"><a href="resampling-methods.html#cross-validation"><i class="fa fa-check"></i><b>10.1</b> Cross-Validation</a><ul>
<li class="chapter" data-level="10.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>10.1.1</b> Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="10.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#cross-validation-1"><i class="fa fa-check"></i><b>10.1.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="10.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#other-quantities"><i class="fa fa-check"></i><b>10.1.3</b> Other Quantities</a></li>
<li class="chapter" data-level="10.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#others"><i class="fa fa-check"></i><b>10.1.4</b> Others</a></li>
<li class="chapter" data-level="10.1.5" data-path="resampling-methods.html"><a href="resampling-methods.html#references-6"><i class="fa fa-check"></i><b>10.1.5</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>11</b> Panel Data</a><ul>
<li class="chapter" data-level="11.1" data-path="panel-data.html"><a href="panel-data.html#longitudinal-data"><i class="fa fa-check"></i><b>11.1</b> Longitudinal Data</a></li>
<li class="chapter" data-level="11.2" data-path="panel-data.html"><a href="panel-data.html#panel-data-1"><i class="fa fa-check"></i><b>11.2</b> Panel Data</a></li>
<li class="chapter" data-level="11.3" data-path="panel-data.html"><a href="panel-data.html#difference-in-difference"><i class="fa fa-check"></i><b>11.3</b> Difference-in-Difference</a></li>
<li class="chapter" data-level="11.4" data-path="panel-data.html"><a href="panel-data.html#tscs"><i class="fa fa-check"></i><b>11.4</b> TSCS</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>12</b> Appendix</a><ul>
<li class="chapter" data-level="12.1" data-path="appendix.html"><a href="appendix.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>12.1</b> Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="references-7.html"><a href="references-7.html"><i class="fa fa-check"></i><b>13</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">POLS 503: Advanced Quantitative Political Methodology: The Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="properties-of-the-ols-estimator-1" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Properties of the OLS Estimator</h1>
<div id="what-makes-an-estimator-good-1" class="section level2">
<h2><span class="header-section-number">3.1</span> What makes an estimator good?</h2>
<blockquote>
<p>A mathematician, a physicist and a statistician went hunting for deer. When they chanced upon one buck lounging about, the mathematician fired first, missing the buck’s nose by a few inches. The physicist then tried his hand, and missed the tail by a wee bit. The statistician started jumping up and down saying “We got him! We got him!”</p>
</blockquote>
<p>Estimators are evaluated not on how close an estimate in a given sample is to the population, but how their sampling distributions compare to the population. In other words, judge the <em>methodology</em> (estimator), not the <em>result</em> (estimate).[^ols-properties-references]</p>
<p>Let <span class="math inline">\(\theta\)</span> be the population parameter, and <span class="math inline">\(\hat\theta\)</span> be an estimator of that population parameter.</p>
<dl>
<dt>Bias</dt>
<dd><p>The bias of an estimator is the difference between the mean of its sampling distribution and the population parameter, <span class="math display">\[\Bias(\hat\theta) = \E(\hat\theta) - \theta .\]</span></p>
</dd>
<dt>Variance</dt>
<dd><p>The variance of the estimator is the variance of its sampling distribution, <span class="math inline">\(\Var(\theta)\)</span>.</p>
</dd>
<dt>Efficiency (Mean squared error)</dt>
<dd><p>An efficient estimator is one that minimizes a given “loss function”, which is a penalty for missing the population average. The most common loss function is squared loss, which gives the <em>Mean Squared Error (MSE)</em> of an estimator.</p>
</dd>
<dd><span class="math display">\[\MSE(\hat\theta) = \E\left[{(\hat\theta - \theta)}^{2}\right] =  (\E(\hat\theta) - \theta)^2 + \E(\hat\theta - \E(\hat\theta))^2 = \Bias(\hat\theta)^2 + \Var(\hat\theta)\]</span>
</dd>
<dd>The mean squared error is a function of both the bias and variance of an estimator.
</dd>
<dd>This means that some biased estimators can be more efficient : than unbiased estimators if their variance offsets their bias.<a href="references-7.html#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>
</dd>
</dl>
<p>Consistency is an asymptotic property<a href="references-7.html#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>, that roughly states that an estimator converges to the truth as the number of observations grows, <span class="math inline">\(\E(\hat\theta - \theta) \to 0\)</span> as <span class="math inline">\(N \to \infty\)</span>. Roughly, this means that if you had enough (infinite) data, the estimator will give you the true value of the parameter.</p>
<div id="properties-of-ols-1" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Properties of OLS</h3>
<table style="width:93%;">
<colgroup>
<col width="29%" />
<col width="29%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assumption</th>
<th align="left">Formal statement</th>
<th align="left">Consequence of violation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">No (perfect) collinearity</td>
<td align="left"><span class="math inline">\(\rank(\mat{X}) = K, K &lt; N\)</span></td>
<td align="left">Coefficients unidentified</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mat{X}\)</span> is exogenous</td>
<td align="left"><span class="math inline">\(\E(\mat{X} \vec{\varepsilon}) = 0\)</span></td>
<td align="left">Biased, even as <span class="math inline">\(N \to \infty\)</span></td>
</tr>
<tr class="odd">
<td align="left">Disturbances have mean 0</td>
<td align="left"><span class="math inline">\(\E(\varepsilon) = 0\)</span></td>
<td align="left">Biased, even as <span class="math inline">\(N \to \infty\)</span></td>
</tr>
<tr class="even">
<td align="left">No serial correlation</td>
<td align="left"><span class="math inline">\(\E(\varepsilon_i \varepsilon_j) = 0\)</span>, <span class="math inline">\(i \neq j\)</span></td>
<td align="left">Unbiased, wrong se</td>
</tr>
<tr class="odd">
<td align="left">Homoskedastic errors</td>
<td align="left"><span class="math inline">\(\E(\vec{\varepsilon}\T \vec{\varepsilon})\)</span></td>
<td align="left">Unbiased, wrong se</td>
</tr>
<tr class="even">
<td align="left">Gaussian errors</td>
<td align="left"><span class="math inline">\(\varepsilon \sim \dnorm(0, \sigma^2)\)</span></td>
<td align="left">Unbiased, se wrong unless <span class="math inline">\(N \to \infty\)</span></td>
</tr>
</tbody>
</table>
<!--
1. Nonlinearity
    - Result: biased/inconsistent estimates
    - Diagnose: scatterplots, added variable plots, component-plus-residual plots
    - Correct: transformations, polynomials, different model
2. iid/random sample
    - Result: no bias with appropriate alternative assumptions (structured dependence)
    - Result (ii): violations imply heteroskedasticity
    - Result (iii): outliers from different distributions can cause inefficiency/bias
    - Diagnose/Correct: next week!
3. Perfect collinearity
    - Result: can't run OLS
    - Diagnose/correct: drop one collinear term
4. Zero conditional mean error
    - Result: biased/inconsistent estimates
    - Diagnose: very difficult
    - Correct: instrumental variables (Gov 2002)
5. Heteroskedasticity
    - Result: SEs are biased (usually downward)
    - Diagnose/correct: next week!
6. Non-Normality
    - Result: critical values for $t$ and $F$ tests wrong
    - Diagnose: checking the (studentized) residuals, QQ-plots, etc
    - Correct: transformations, add variables to $\X$, different model
-->
<p>Note that these assumptions can be sometimes be written in largely equivalent, but slightly different forms.</p>
<p>When is a variable <em>endogenous</em></p>
<ol style="list-style-type: decimal">
<li>Omitted variables</li>
<li>Measurement error</li>
<li>Simultaneity</li>
</ol>
<p>Assumptions of CLR models</p>
<ol style="list-style-type: decimal">
<li>No perfect collinearity: No exact linear relationships in the predictors. <span class="math inline">\(X\)</span> is full rank.</li>
<li>Linearity: Outcome variable is a linear function of a specific set of independent variables and a disturbance: <span class="math display">\[\vec{y} = \mat{X} \vec{\beta} + \vec{\varepsilon}\]</span>.</li>
<li>Observations on independent samples can be considered fixed in repeated samples or <span class="math inline">\(X\)</span> is uncorrelated with the errors.</li>
<li>Expected value of the disturbance term is zero.</li>
<li>Homoskedasticity: Disturbances have the same variance and are uncorrelated: <span class="math inline">\(\var(\varepsilon_i) = \sigma^2\)</span>, <span class="math inline">\(\cov(\varepsilon_i, \varepsilon_j) = 0\)</span> for all <span class="math inline">\(i \neq j\)</span>.</li>
<li>Error terms are distributed normal.</li>
</ol>
<ul>
<li>OLS solution exists with unique <span class="math inline">\(\beta\)</span>: 1</li>
<li>OLS is unbiased and consistent: 1-4</li>
<li>OLS is best-linear unbiased estimator (BLUE) Gauss-Markov. Large scale inference. 1-5.</li>
<li>OLS small scale inference: 1-6. Best unbiased estimator (not just among linear)</li>
</ul>
<p>Why OLS?</p>
<ul>
<li>Computational cost: There exists a closed form solution to the OLS estimate and standard errors.</li>
<li>Least squares loss: OLS minimizes least squared residuals, and thus is optimal for this criteria. Note, that this is only for within sample.</li>
<li>Hightest R^2: Follows from the previous.</li>
<li>Unbiased:</li>
<li>Best unbiased:</li>
<li>Mean squared error: OLS is <strong>not</strong> the minimum MSE model.</li>
<li>Asymptotic criteria: Asymptotically unbiased and consitent.</li>
<li>Maximum likelihood: OLS is equivalent to the MLE estimator for <span class="math inline">\(\beta\)</span>.</li>
</ul>
</div>
</div>
<div id="references-1" class="section level2">
<h2><span class="header-section-number">3.2</span> References</h2>
<ul>
<li>Wooldrige, Ch 3.</li>
<li>Fox, Ch 6, 9.</li>
</ul>
</div>
<div id="sampling-distribution-of-ols-coefficients" class="section level2">
<h2><span class="header-section-number">3.3</span> Sampling Distribution of OLS Coefficients</h2>
</div>
<div id="t-tests-for-single-parameters" class="section level2">
<h2><span class="header-section-number">3.4</span> t-tests for single parameters</h2>
<p>The sampling distribution of the OLS parameters is <span class="math display">\[
\vec{\beta} \sim \dmvnorm(\vec{beta}, \sigma^2 (\mat{X}&#39; \mat{X})^{-1}).
\]</span> Thus, the variance of the coefficients is <span class="math display">\[
\Var(\hat{\beta}) = \sigma^2 (\mat{X}&#39; \mat{X})^{-1} .
\]</span> which is a symmetric matrix, <span class="math display">\[
\Var(\hat{\beta}) =
\begin{bmatrix}
\Var(\hat{\beta}_0) &amp; \Cov(\hat{\beta}_0, \hat{\beta}_1) &amp; \Cov(\hat{\beta}_0, \hat{\beta}_1) &amp; \cdots &amp; \Cov(\hat{\beta}_0, \hat{\beta}_K) \\
\Cov(\hat{\beta}_0, \hat{\beta}_1) &amp; \Var(\hat{\beta}_1) &amp; \Cov(\hat{\beta}_1, \hat{\beta}_2) &amp; \cdots &amp; \Cov(\hat{\beta}_1, \hat{\beta}_K) \\
\Cov(\hat{\beta}_0, \hat{\beta}_2) &amp; \Cov(\hat{\beta}_1, \hat{\beta}_2) &amp; \Cov(\hat{\beta}_2) &amp; \cdots &amp; \Cov(\hat{\beta}_2, \hat{\beta}_K) \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\Cov(\hat{\beta}_0, \hat{\beta}_K) &amp; \Cov(\hat{\beta}_1, \hat{\beta}_K) &amp; \Cov(\hat{\beta}_K) &amp; \cdots &amp; \Var( \hat{\beta}_k)
\end{bmatrix}
\]</span> On the diagonal are the variances of the parameters, and the off-diagonal elements are the covariances of the parameters.</p>
<p>The null hypothesis and alternative hypotheses for two-sided tests are, <span class="math display">\[
\begin{aligned}[t]
H_0: &amp;\beta_k = \beta_0 \\
H_a: &amp;\beta_k \neq \beta_0
\end{aligned}
\]</span></p>
<p>Then in large samples, <span class="math display">\[
\frac{\hat{\beta}_k - \beta_k}{\se(\widehat{\beta}_k)} \sim \dnorm(0, 1)
\]</span> In small samples, <span class="math display">\[
\frac{\hat{\beta}_k - \beta_k}{\se(\widehat{\beta}_k)} \sim \dt{N - (K + 1)}
\]</span></p>
<p>The estimated standard errors of <span class="math inline">\(\hat{\beta}\)</span> come from <span class="math display">\[
\begin{aligned}[t]
\var(\hat{\vec{\beta}}) &amp;= \hat{\sigma}^2 (\mat{X}&#39; \mat{X})^{-1} \\
\hat{\sigma}^2 &amp;= \frac{\vec{\epsilon}&#39;\vec{epsilon}}{(N - (K + 1))}
\end{aligned}
\]</span></p>
<p>So, under the common null hypothesis test for <span class="math inline">\(\beta_k = 0\)</span>, <span class="math display">\[
\frac{\hat{\beta}_k}{\se(\widehat{\beta}_k)} \sim \dt{N - (K + 1)}
\]</span></p>
<p>And the confidence intervals for a <span class="math inline">\((1 - \alpha) \times 100\)</span> confidence interval for <span class="math inline">\(\hat{\beta}_k\)</span> are, <span class="math display">\[
\hat{\beta}_k \pm t^*_{\alpha / 2} \times \se(\hat{\beta}_K)
\]</span> where <span class="math inline">\(t^*_{\alpha / 2}\)</span> is the quantile of the <span class="math inline">\(\dt_{n - (K + 1)}\)</span> distribution such that <span class="math inline">\(P(T \leq t^*) &gt; 1 - \alpha / 2\)</span>.</p>
</div>
<div id="f-tests-of-multiple-hypotheses" class="section level2">
<h2><span class="header-section-number">3.5</span> F-tests of Multiple Hypotheses</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-and-the-ordinary-least-squares-ols-estimator.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="omitted-variable-bias-and-measurement-error.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/UW-POLS503/pols503-notes/edit/gh-pages/ols-inference.Rmd",
"text": "Edit"
},
"download": ["pols503-notes.pdf", "pols503-notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>


</body>

</html>
