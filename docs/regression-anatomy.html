<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Analysis Notes</title>
  <meta name="description" content="These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.">
  <meta name="generator" content="bookdown 0.7.7 and GitBook 2.6.7">

  <meta property="og:title" content="Data Analysis Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington." />
  <meta name="github-repo" content="jrnold/intro-methods-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Analysis Notes" />
  
  <meta name="twitter:description" content="These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington." />
  

<meta name="author" content="Jeffrey B. Arnold">


<meta name="date" content="2018-04-17">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="ols-in-matrix-form.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro Method Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="part"><span><b>I Exploratory Data Analysis</b></span></li>
<li class="part"><span><b>II Programming</b></span></li>
<li class="part"><span><b>III Linear Regression</b></span></li>
<li class="chapter" data-level="2" data-path="regression-anatomy.html"><a href="regression-anatomy.html"><i class="fa fa-check"></i><b>2</b> Regression Anatomy</a><ul>
<li class="chapter" data-level="2.1" data-path="regression-anatomy.html"><a href="regression-anatomy.html#example"><i class="fa fa-check"></i><b>2.1</b> Example</a></li>
<li class="chapter" data-level="2.2" data-path="regression-anatomy.html"><a href="regression-anatomy.html#variations"><i class="fa fa-check"></i><b>2.2</b> Variations</a></li>
<li class="chapter" data-level="2.3" data-path="regression-anatomy.html"><a href="regression-anatomy.html#questions"><i class="fa fa-check"></i><b>2.3</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html"><i class="fa fa-check"></i><b>3</b> OLS in Matrix Form</a><ul>
<li class="chapter" data-level="" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#setup"><i class="fa fa-check"></i>Setup</a></li>
<li class="chapter" data-level="3.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#purpose"><i class="fa fa-check"></i><b>3.1</b> Purpose</a></li>
<li class="chapter" data-level="3.2" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrix-algebra-review"><i class="fa fa-check"></i><b>3.2</b> Matrix Algebra Review</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrices"><i class="fa fa-check"></i><b>3.2.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrix-operations"><i class="fa fa-check"></i><b>3.3</b> Matrix Operations</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#transpose"><i class="fa fa-check"></i><b>3.3.1</b> Transpose</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrices-as-vectors"><i class="fa fa-check"></i><b>3.4</b> Matrices as vectors</a></li>
<li class="chapter" data-level="3.5" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#special-matrices"><i class="fa fa-check"></i><b>3.5</b> Special matrices</a></li>
<li class="chapter" data-level="3.6" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#multiple-linear-regression-in-matrix-form"><i class="fa fa-check"></i><b>3.6</b> Multiple linear regression in matrix form</a></li>
<li class="chapter" data-level="3.7" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#residuals"><i class="fa fa-check"></i><b>3.7</b> Residuals</a></li>
<li class="chapter" data-level="3.8" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#scalar-inverses"><i class="fa fa-check"></i><b>3.8</b> Scalar inverses</a></li>
<li class="chapter" data-level="3.9" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrix-inverses"><i class="fa fa-check"></i><b>3.9</b> Matrix Inverses</a></li>
<li class="chapter" data-level="3.10" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#ols-estimator"><i class="fa fa-check"></i><b>3.10</b> OLS Estimator</a></li>
<li class="chapter" data-level="3.11" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#implications-of-ols"><i class="fa fa-check"></i><b>3.11</b> Implications of OLS</a><ul>
<li class="chapter" data-level="3.11.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#ols-in-matrix-form-1"><i class="fa fa-check"></i><b>3.11.1</b> OLS in Matrix Form</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#covariancevariance-interpretation-of-ols"><i class="fa fa-check"></i><b>3.12</b> Covariance/variance interpretation of OLS</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html"><i class="fa fa-check"></i><b>4</b> collinearity and Multicollinearity</a><ul>
<li class="chapter" data-level="4.1" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#perfect-collinearity"><i class="fa fa-check"></i><b>4.1</b> (Perfect) collinearity</a></li>
<li class="chapter" data-level="4.2" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#what-to-do-about-it"><i class="fa fa-check"></i><b>4.2</b> What to do about it?</a></li>
<li class="chapter" data-level="4.3" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#multicollinearity"><i class="fa fa-check"></i><b>4.3</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.4" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#what-do-do-about-it"><i class="fa fa-check"></i><b>4.4</b> What do do about it?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>5</b> Prediction</a><ul>
<li class="chapter" data-level="" data-path="prediction.html"><a href="prediction.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="5.1" data-path="prediction.html"><a href="prediction.html#prediction-questions-vs.causal-questions"><i class="fa fa-check"></i><b>5.1</b> Prediction Questions vs. Causal Questions</a></li>
<li class="chapter" data-level="5.2" data-path="prediction.html"><a href="prediction.html#why-is-prediction-important"><i class="fa fa-check"></i><b>5.2</b> Why is prediction important?</a></li>
<li class="chapter" data-level="5.3" data-path="prediction.html"><a href="prediction.html#many-problems-are-prediction-problems"><i class="fa fa-check"></i><b>5.3</b> Many problems are prediction problems</a><ul>
<li class="chapter" data-level="5.3.1" data-path="prediction.html"><a href="prediction.html#counterfactuals"><i class="fa fa-check"></i><b>5.3.1</b> Counterfactuals</a></li>
<li class="chapter" data-level="5.3.2" data-path="prediction.html"><a href="prediction.html#controls"><i class="fa fa-check"></i><b>5.3.2</b> Controls</a></li>
<li class="chapter" data-level="5.3.3" data-path="prediction.html"><a href="prediction.html#what-does-overfitting-mean"><i class="fa fa-check"></i><b>5.3.3</b> What does overfitting mean</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="prediction.html"><a href="prediction.html#prediction-vs.explanation"><i class="fa fa-check"></i><b>5.4</b> Prediction vs. Explanation</a></li>
<li class="chapter" data-level="5.5" data-path="prediction.html"><a href="prediction.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>5.5</b> Bias-Variance Tradeoff</a><ul>
<li class="chapter" data-level="5.5.1" data-path="prediction.html"><a href="prediction.html#example-1"><i class="fa fa-check"></i><b>5.5.1</b> Example</a></li>
<li class="chapter" data-level="5.5.2" data-path="prediction.html"><a href="prediction.html#overview"><i class="fa fa-check"></i><b>5.5.2</b> Overview</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="prediction.html"><a href="prediction.html#prediction-policy-problems"><i class="fa fa-check"></i><b>5.6</b> Prediction policy problems</a></li>
<li class="chapter" data-level="5.7" data-path="prediction.html"><a href="prediction.html#freedmans-paradox"><i class="fa fa-check"></i><b>5.7</b> Freedman’s Paradox</a><ul>
<li class="chapter" data-level="5.7.1" data-path="prediction.html"><a href="prediction.html#references"><i class="fa fa-check"></i><b>5.7.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Presentation</b></span></li>
<li class="chapter" data-level="6" data-path="formatting-tables.html"><a href="formatting-tables.html"><i class="fa fa-check"></i><b>6</b> Formatting Tables</a><ul>
<li class="chapter" data-level="6.1" data-path="formatting-tables.html"><a href="formatting-tables.html#overview-of-packages"><i class="fa fa-check"></i><b>6.1</b> Overview of Packages</a></li>
<li class="chapter" data-level="6.2" data-path="formatting-tables.html"><a href="formatting-tables.html#summary-statistic-table-example"><i class="fa fa-check"></i><b>6.2</b> Summary Statistic Table Example</a></li>
<li class="chapter" data-level="6.3" data-path="formatting-tables.html"><a href="formatting-tables.html#regression-table-example"><i class="fa fa-check"></i><b>6.3</b> Regression Table Example</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reproducible-research.html"><a href="reproducible-research.html"><i class="fa fa-check"></i><b>7</b> Reproducible Research</a></li>
<li class="chapter" data-level="8" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html"><i class="fa fa-check"></i><b>8</b> Typesetting and Word Processing Programs</a><ul>
<li class="chapter" data-level="8.1" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#latex"><i class="fa fa-check"></i><b>8.1</b> LaTeX</a><ul>
<li class="chapter" data-level="8.1.1" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#learning-latex"><i class="fa fa-check"></i><b>8.1.1</b> Learning LaTeX</a></li>
<li class="chapter" data-level="8.1.2" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#using-latex"><i class="fa fa-check"></i><b>8.1.2</b> Using LaTeX</a></li>
<li class="chapter" data-level="8.1.3" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#latex-with-r"><i class="fa fa-check"></i><b>8.1.3</b> LaTeX with R</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#word"><i class="fa fa-check"></i><b>8.2</b> Word</a><ul>
<li class="chapter" data-level="8.2.1" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#general-advice"><i class="fa fa-check"></i><b>8.2.1</b> General Advice</a></li>
<li class="chapter" data-level="8.2.2" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#using-r-with-word"><i class="fa fa-check"></i><b>8.2.2</b> Using R with Word</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="writing-resources.html"><a href="writing-resources.html"><i class="fa fa-check"></i><b>9</b> Writing Resources</a><ul>
<li class="chapter" data-level="9.1" data-path="writing-resources.html"><a href="writing-resources.html#writing-and-organizing-papers"><i class="fa fa-check"></i><b>9.1</b> Writing and Organizing Papers</a></li>
<li class="chapter" data-level="9.2" data-path="writing-resources.html"><a href="writing-resources.html#finding-research-ideas"><i class="fa fa-check"></i><b>9.2</b> Finding Research Ideas</a></li>
<li class="chapter" data-level="9.3" data-path="writing-resources.html"><a href="writing-resources.html#replications"><i class="fa fa-check"></i><b>9.3</b> Replications</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\Mat}[1]{\boldsymbol{#1}}
\newcommand{\Vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

\newcommand{\distr}[1]{\mathcal{#1}}
\newcommand{\dnorm}{\distr{N}}
\newcommand{\dmvnorm}[1]{\distr{N}_{#1}}
\newcommand{\dt}[1]{\distr{T}_{#1}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="regression-anatomy" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Regression Anatomy</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</code></pre>
<p>Summary: The coefficient of <span class="math inline">\(x\)</span> in a multiple regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> is equivalent to regressing <span class="math inline">\(y\)</span> on the part of <span class="math inline">\(x\)</span> not explained by <span class="math inline">\(z\)</span> (the residuals of a regression of <span class="math inline">\(x\)</span> on <span class="math inline">\(z\)</span>)</p>
<p><em>Regression anatomy</em> is a term from <span class="citation">Angrist and Pischke (<a href="#ref-AngristPischke2009a">2009</a>)</span> for the coefficient of variable <span class="math inline">\(x\)</span> linear regression in a multiple regression is equivalent to the coefficient of a bivariate model using the residual from a regression of that variable regressed on all the other variables.
Regression anatomy provides an answer to the <em>how</em> of control variables work.</p>
<p>Consider a regression with two predictors,
<span class="math display">\[
\Vec{y} = \beta_0 + \beta_1 \Vec{x}_1  + \beta_1 \Vec{x}_2 + u .
\]</span></p>
<p>The OLS estimator of <span class="math inline">\(\beta\)</span> is
<span class="math display">\[
(\beta_1, \beta_2) = \Vec{\beta} = (\Mat{X}&#39;\Mat{X})^{-1} \Mat{X}&#39; \Vec{y}
\]</span></p>
<p>We can also recover the OLS estimate of <span class="math inline">\(\beta_1\)</span> through two bivariate regressions and the following procedure.</p>
<p><span class="math display">\[
\beta_1 = \frac{\Cov(\Vec{y}, \tilde{\Vec{u}})}{\Var(\tilde{\Vec{u}})} .
\]</span>
where <span class="math inline">\(\tilde{\Vec{u}}\)</span> is the vector of residuals from the regression of <span class="math inline">\(\Vec{x}_1\)</span> on <span class="math inline">\(\Vec{x}_2\)</span>,
<span class="math display">\[
\begin{aligned}[t]
\Vec{x}_1 = \gamma_0 + \gamma_1 \Vec{x}_2 + v .
\end{aligned}
\]</span>
This can be extended to more than two two variables by repeating the above steps as many times as necessary.</p>
<p>This result is called the Frisch, Waugh, and Lovell (FWL) and discussed in Angrist and Pischke (2009).
A complete proof can be found in advanced econometrics textbooks such as Davidson and MacKinnon (1993, p. 19–24) or Ruud (2000, p. 54–60).</p>
<p>Note:</p>
<ul>
<li>This is a mechanical property of OLS</li>
<li>It does depend an underlying Data Generating Process (DGP).</li>
<li>Nevertheless, useful for understanding how OLS can be used for causal inference</li>
</ul>
<div id="example" class="section level2">
<h2><span class="header-section-number">2.1</span> Example</h2>
<p>For this example we will use the <code>Duncan</code> data from the <strong>car</strong> package.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;Duncan&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;carData&quot;</span>)
Duncan &lt;-<span class="st"> </span><span class="kw">rownames_to_column</span>(Duncan, <span class="dt">var =</span> <span class="st">&quot;occupation&quot;</span>)</code></pre>
<p>Regress <code>prestige</code> on <code>education</code> and <code>income</code> using <code>lm</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mod1 &lt;-<span class="st"> </span><span class="kw">lm</span>(prestige <span class="op">~</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>income, <span class="dt">data =</span> Duncan)
mod1</code></pre>
<pre><code>## 
## Call:
## lm(formula = prestige ~ education + income, data = Duncan)
## 
## Coefficients:
## (Intercept)    education       income  
##     -6.0647       0.5458       0.5987</code></pre>
<p>Now, use the regression anatomy methods to find the regression of <code>education</code> by regression anatomy methods:
Regress <code>education</code> on <code>income</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">mod2a &lt;-<span class="st"> </span><span class="kw">lm</span>(education <span class="op">~</span><span class="st"> </span>income, <span class="dt">data =</span> Duncan)
mod2a</code></pre>
<pre><code>## 
## Call:
## lm(formula = education ~ income, data = Duncan)
## 
## Coefficients:
## (Intercept)       income  
##     15.6114       0.8824</code></pre>
<p>Store the residuals from that regression.
For convenience, use the <code>augment</code> function from the <strong>broom</strong> package.</p>
<pre class="sourceCode r"><code class="sourceCode r">Duncan &lt;-<span class="st"> </span>modelr<span class="op">::</span><span class="kw">add_residuals</span>(Duncan, mod2a, <span class="dt">var =</span> <span class="st">&quot;resid_education&quot;</span>)</code></pre>
<p>Regress <code>prestige</code> on the residuals of <code>education</code> regressed on `</p>
<pre class="sourceCode r"><code class="sourceCode r">mod2b &lt;-<span class="st"> </span><span class="kw">lm</span>(prestige <span class="op">~</span><span class="st"> </span>resid_education, <span class="dt">data =</span> Duncan)
mod2b</code></pre>
<pre><code>## 
## Call:
## lm(formula = prestige ~ resid_education, data = Duncan)
## 
## Coefficients:
##     (Intercept)  resid_education  
##         47.6889           0.5458</code></pre>
<p>The coefficients of these two regressions are approximately equal.
They are different due to floating point rounding errors.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(mod1)[<span class="st">&quot;education&quot;</span>] <span class="op">-</span><span class="st"> </span><span class="kw">coef</span>(mod2b)[<span class="st">&quot;resid_education&quot;</span>]</code></pre>
<pre><code>##    education 
## 1.110223e-16</code></pre>
<p><strong>Q:</strong> Plot the regression lines</p>
<pre class="sourceCode r"><code class="sourceCode r">Duncan <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(prestige, education, resid_education) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>prestige) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">variable =</span> dplyr<span class="op">::</span><span class="kw">recode</span>(variable, <span class="dt">resid_education =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="dt">education =</span> <span class="st">&quot;education&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">y =</span> prestige, <span class="dt">colour =</span> variable)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="reganat_files/figure-html/unnamed-chunk-3-1.svg" width="672" /></p>
</div>
<div id="variations" class="section level2">
<h2><span class="header-section-number">2.2</span> Variations</h2>
<p>Let’s consider a couple of variations.</p>
<p>First, consider the case in which we regress the residuals from <span class="math inline">\(y\)</span> regressed on <span class="math inline">\(x_2\)</span> on the residuals of <span class="math inline">\(x_1\)</span> regressed on <span class="math inline">\(x_2\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Regress <span class="math inline">\(y\)</span> on <span class="math inline">\(x_2\)</span>. Let <span class="math inline">\(\tilde{y}\)</span> be the residuals from that regression.</li>
<li>Regress <span class="math inline">\(x_1\)</span> on <span class="math inline">\(x_2\)</span>. Let <span class="math inline">\(\tilde{x}_1\)</span> be the residuals from that regression.</li>
<li>Regress <span class="math inline">\(\tilde{y}\)</span> on <span class="math inline">\(\tilde{x}_1\)</span>; do not include an intercept.</li>
</ol>
<p><strong>Q:</strong> Will the coefficient of <span class="math inline">\(\tilde{x}_1\)</span> be the same as in the first case?</p>
<p><strong>Q:</strong> In the last stage why is there no intercept?</p>
<p>Return to the previous example using the Duncan occupational prestige data.
Regress <code>prestige</code> on <code>income</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mod3 &lt;-<span class="st"> </span><span class="kw">lm</span>(prestige <span class="op">~</span><span class="st"> </span>income, <span class="dt">data =</span> Duncan)
mod3</code></pre>
<pre><code>## 
## Call:
## lm(formula = prestige ~ income, data = Duncan)
## 
## Coefficients:
## (Intercept)       income  
##       2.457        1.080</code></pre>
<p>Add the residuals from this regression to Duncan dataset.</p>
<pre class="sourceCode r"><code class="sourceCode r">Duncan &lt;-<span class="st"> </span>modelr<span class="op">::</span><span class="kw">add_residuals</span>(Duncan, mod3, <span class="dt">var =</span> <span class="st">&quot;resid_prestige&quot;</span>)</code></pre>
<p>Regress the residuals of from the regression of <code>prestige</code> on <code>income</code> on the residuals from the regression of <code>income</code> on <code>education</code>.
Do not include an intercept.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(resid_prestige <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>resid_education, <span class="dt">data =</span> Duncan)</code></pre>
<pre><code>## 
## Call:
## lm(formula = resid_prestige ~ 0 + resid_education, data = Duncan)
## 
## Coefficients:
## resid_education  
##          0.5458</code></pre>
<p>What happens if we don’t include the intercept?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(resid_prestige <span class="op">~</span><span class="st">  </span>resid_education, <span class="dt">data =</span> Duncan)</code></pre>
<pre><code>## 
## Call:
## lm(formula = resid_prestige ~ resid_education, data = Duncan)
## 
## Coefficients:
##     (Intercept)  resid_education  
##      -8.904e-16        5.458e-01</code></pre>
<p>The intercept is estimate to be approximately zero - since the the regression line must go through <span class="math inline">\((\bar{y}, \bar{x})\)</span> and residuals have mean 0.</p>
<p>Plot the residuals and their regression line against the original values and their regression line.
Subtract the mean from <code>prestige</code> and <code>income</code> so both linear regression lines go through the origin, which make it easier to compare them.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bind_rows</span>(<span class="kw">mutate</span>(<span class="kw">select</span>(Duncan, occupation, prestige, education),
                 <span class="dt">residuals =</span> <span class="ot">FALSE</span>,
                 <span class="dt">prestige =</span> prestige <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(prestige),
                 <span class="dt">education =</span> education <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(education)),
          <span class="kw">mutate</span>(<span class="kw">select</span>(Duncan, occupation, <span class="dt">prestige =</span> resid_prestige,
                        <span class="dt">education =</span> resid_education),
                 <span class="dt">residuals =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> education, <span class="dt">y =</span> prestige, <span class="dt">colour =</span> residuals)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="reganat_files/figure-html/unnamed-chunk-7-1.svg" width="672" /></p>
<p>Second, consider the case in which we regress the residuals from <span class="math inline">\(y\)</span> regressed on <span class="math inline">\(x_2\)</span> on <span class="math inline">\(x_1\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Regress <span class="math inline">\(y\)</span> on <span class="math inline">\(x_2\)</span>. Let <span class="math inline">\(\tilde{y}\)</span> be the residuals from that regression.</li>
<li>Regress <span class="math inline">\(\tilde{y}\)</span> on <span class="math inline">\(x_1\)</span>.</li>
</ol>
<p>Regress the residuals of the regression of <code>prestige</code> on <code>income</code> on <code>education</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(resid_prestige <span class="op">~</span><span class="st"> </span>education, <span class="dt">data =</span> Duncan)</code></pre>
<pre><code>## 
## Call:
## lm(formula = resid_prestige ~ education, data = Duncan)
## 
## Coefficients:
## (Intercept)    education  
##    -13.6285       0.2593</code></pre>
<p>The coefficient on <code>education</code> is not the same as the multivariate OLS coefficient.
In this case, we have not “controlled” for anything.
The coefficient of <code>education</code> still includes the relationship between <code>income</code> and
<code>education</code>.</p>
</div>
<div id="questions" class="section level2">
<h2><span class="header-section-number">2.3</span> Questions</h2>
<ol style="list-style-type: decimal">
<li><p>How does the variance of a variable compare to the variance of its residuals after regressing it on other control variables?
What is the implication of that result for its standard error?</p></li>
<li><p>If two variables are co-linear what is the residual after the first stage?
How does that explain why OLS cannot estimate a linear regression with collinear variables.</p></li>
<li><p>Suppose that two variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are highly correlated.
In the first stage you regress <span class="math inline">\(x_1\)</span> on <span class="math inline">\(x_2\)</span>.
What do you expect the coefficient of <span class="math inline">\(x_2\)</span> to be?
What do you expect the residuals of this regression to be?
How do you expect the coefficient of <span class="math inline">\(x_1\)</span> on</p></li>
<li><p>Consider two highly correlated variables.
What are the implications for this in the first stage and second stage of regression anatomy?</p></li>
<li><p>Confirm that regression anatomy also works for the coefficient of <code>income</code> in the previous regressions.</p></li>
<li><p>Conduct regression anatomy for the coefficient of <code>education</code> in</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(prestige <span class="op">~</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>type, <span class="dt">data =</span> Duncan)</code></pre>
<p>In this case we have a continuous variable (<code>education</code>) and a discrete control (<code>type</code>).
How do would you interpret the residuals of the regression of <code>education</code> on <code>type</code>?</p></li>
<li><p>Does the second stage of regression anatomy produce the correct standard errors?
Informally, why do you think that is not the case.
Retaining the regression anatomy procedure, generate correct standard errors using resampling.</p></li>
<li><p>In causal inference, informally “selection on observables” attempts to estimate a causal effect by comparing “similar” observations.
How does and doesn’t linear regression do this?</p></li>
<li><p>Using the results of regression anatomy, how would you expect omitting control variables to effect the coefficients of a variable?</p></li>
<li><p>Recall that the slope of a linear regression coefficient can be represented as a weighted average of the outcome variable,
<span class="math display">\[
\hat{\beta} = \sum_{i = 1}^n w_i y_i
\]</span>
where
<span class="math display">\[
w_i = \frac{(x_i - \bar{x})}{\sum_{i = 1} (x_i - \bar{x})^2} .
\]</span>
Given regression anatomy, what are the weights of observations in multiple regression?</p></li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-AngristPischke2009a">
<p>Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Pr.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ols-in-matrix-form.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/intro-method-notes/edit/master/reganat.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
