<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Analysis Notes</title>
  <meta name="description" content="These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Data Analysis Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington." />
  <meta name="github-repo" content="jrnold/intro-methods-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Analysis Notes" />
  
  <meta name="twitter:description" content="These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington." />
  

<meta name="author" content="Jeffrey B. Arnold">


<meta name="date" content="2018-05-07">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regularization.html">
<link rel="next" href="panel-data-fixed-effects-and-difference-in-difference.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro Method Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="part"><span><b>I Exploratory Data Analysis</b></span></li>
<li class="part"><span><b>II Programming</b></span></li>
<li class="part"><span><b>III Linear Regression</b></span></li>
<li class="chapter" data-level="2" data-path="regression-anatomy.html"><a href="regression-anatomy.html"><i class="fa fa-check"></i><b>2</b> Regression Anatomy</a><ul>
<li class="chapter" data-level="2.1" data-path="regression-anatomy.html"><a href="regression-anatomy.html#example"><i class="fa fa-check"></i><b>2.1</b> Example</a></li>
<li class="chapter" data-level="2.2" data-path="regression-anatomy.html"><a href="regression-anatomy.html#variations"><i class="fa fa-check"></i><b>2.2</b> Variations</a></li>
<li class="chapter" data-level="2.3" data-path="regression-anatomy.html"><a href="regression-anatomy.html#questions"><i class="fa fa-check"></i><b>2.3</b> Questions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html"><i class="fa fa-check"></i><b>3</b> OLS in Matrix Form</a><ul>
<li class="chapter" data-level="" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#setup"><i class="fa fa-check"></i>Setup</a></li>
<li class="chapter" data-level="3.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#purpose"><i class="fa fa-check"></i><b>3.1</b> Purpose</a></li>
<li class="chapter" data-level="3.2" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrix-algebra-review"><i class="fa fa-check"></i><b>3.2</b> Matrix Algebra Review</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrices"><i class="fa fa-check"></i><b>3.2.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrix-operations"><i class="fa fa-check"></i><b>3.3</b> Matrix Operations</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#transpose"><i class="fa fa-check"></i><b>3.3.1</b> Transpose</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrices-as-vectors"><i class="fa fa-check"></i><b>3.4</b> Matrices as vectors</a></li>
<li class="chapter" data-level="3.5" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#special-matrices"><i class="fa fa-check"></i><b>3.5</b> Special matrices</a></li>
<li class="chapter" data-level="3.6" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#multiple-linear-regression-in-matrix-form"><i class="fa fa-check"></i><b>3.6</b> Multiple linear regression in matrix form</a></li>
<li class="chapter" data-level="3.7" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#residuals"><i class="fa fa-check"></i><b>3.7</b> Residuals</a></li>
<li class="chapter" data-level="3.8" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#scalar-inverses"><i class="fa fa-check"></i><b>3.8</b> Scalar inverses</a></li>
<li class="chapter" data-level="3.9" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#matrix-inverses"><i class="fa fa-check"></i><b>3.9</b> Matrix Inverses</a></li>
<li class="chapter" data-level="3.10" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#ols-estimator"><i class="fa fa-check"></i><b>3.10</b> OLS Estimator</a></li>
<li class="chapter" data-level="3.11" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#implications-of-ols"><i class="fa fa-check"></i><b>3.11</b> Implications of OLS</a><ul>
<li class="chapter" data-level="3.11.1" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#ols-in-matrix-form-1"><i class="fa fa-check"></i><b>3.11.1</b> OLS in Matrix Form</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="ols-in-matrix-form.html"><a href="ols-in-matrix-form.html#covariancevariance-interpretation-of-ols"><i class="fa fa-check"></i><b>3.12</b> Covariance/variance interpretation of OLS</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html"><i class="fa fa-check"></i><b>4</b> Collinearity and Multicollinearity</a><ul>
<li class="chapter" data-level="4.1" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#perfect-collinearity"><i class="fa fa-check"></i><b>4.1</b> (Perfect) collinearity</a></li>
<li class="chapter" data-level="4.2" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#what-to-do-about-it"><i class="fa fa-check"></i><b>4.2</b> What to do about it?</a></li>
<li class="chapter" data-level="4.3" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#multicollinearity"><i class="fa fa-check"></i><b>4.3</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.4" data-path="collinearity-and-multicollinearity.html"><a href="collinearity-and-multicollinearity.html#what-do-do-about-it"><i class="fa fa-check"></i><b>4.4</b> What do do about it?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bootstrapping.html"><a href="bootstrapping.html"><i class="fa fa-check"></i><b>5</b> Bootstrapping</a><ul>
<li class="chapter" data-level="5.1" data-path="bootstrapping.html"><a href="bootstrapping.html#non-parametric-bootstrap"><i class="fa fa-check"></i><b>5.1</b> Non-parametric bootstrap</a></li>
<li class="chapter" data-level="5.2" data-path="bootstrapping.html"><a href="bootstrapping.html#standard-errors"><i class="fa fa-check"></i><b>5.2</b> Standard Errors</a></li>
<li class="chapter" data-level="5.3" data-path="bootstrapping.html"><a href="bootstrapping.html#confidence-intervals"><i class="fa fa-check"></i><b>5.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.4" data-path="bootstrapping.html"><a href="bootstrapping.html#alternative-methods"><i class="fa fa-check"></i><b>5.4</b> Alternative methods</a><ul>
<li class="chapter" data-level="5.4.1" data-path="bootstrapping.html"><a href="bootstrapping.html#parametric-bootstrap"><i class="fa fa-check"></i><b>5.4.1</b> Parametric Bootstrap</a></li>
<li class="chapter" data-level="5.4.2" data-path="bootstrapping.html"><a href="bootstrapping.html#clustered-bootstrap"><i class="fa fa-check"></i><b>5.4.2</b> Clustered bootstrap</a></li>
<li class="chapter" data-level="5.4.3" data-path="bootstrapping.html"><a href="bootstrapping.html#time-series-bootstrap"><i class="fa fa-check"></i><b>5.4.3</b> Time series bootstrap</a></li>
<li class="chapter" data-level="5.4.4" data-path="bootstrapping.html"><a href="bootstrapping.html#how-to-sample"><i class="fa fa-check"></i><b>5.4.4</b> How to sample?</a></li>
<li class="chapter" data-level="5.4.5" data-path="bootstrapping.html"><a href="bootstrapping.html#caveats"><i class="fa fa-check"></i><b>5.4.5</b> Caveats</a></li>
<li class="chapter" data-level="5.4.6" data-path="bootstrapping.html"><a href="bootstrapping.html#why-use-bootstrapping"><i class="fa fa-check"></i><b>5.4.6</b> Why use bootstrapping?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="bootstrapping.html"><a href="bootstrapping.html#bagging"><i class="fa fa-check"></i><b>5.5</b> Bagging</a></li>
<li class="chapter" data-level="5.6" data-path="bootstrapping.html"><a href="bootstrapping.html#hypothesis-testing"><i class="fa fa-check"></i><b>5.6</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.7" data-path="bootstrapping.html"><a href="bootstrapping.html#how-many-samples"><i class="fa fa-check"></i><b>5.7</b> How many samples?</a></li>
<li class="chapter" data-level="5.8" data-path="bootstrapping.html"><a href="bootstrapping.html#references"><i class="fa fa-check"></i><b>5.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>6</b> Prediction</a><ul>
<li class="chapter" data-level="" data-path="prediction.html"><a href="prediction.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="6.1" data-path="prediction.html"><a href="prediction.html#prediction-questions-vs.causal-questions"><i class="fa fa-check"></i><b>6.1</b> Prediction Questions vs. Causal Questions</a></li>
<li class="chapter" data-level="6.2" data-path="prediction.html"><a href="prediction.html#why-is-prediction-important"><i class="fa fa-check"></i><b>6.2</b> Why is prediction important?</a></li>
<li class="chapter" data-level="6.3" data-path="prediction.html"><a href="prediction.html#many-problems-are-prediction-problems"><i class="fa fa-check"></i><b>6.3</b> Many problems are prediction problems</a><ul>
<li class="chapter" data-level="6.3.1" data-path="prediction.html"><a href="prediction.html#counterfactuals"><i class="fa fa-check"></i><b>6.3.1</b> Counterfactuals</a></li>
<li class="chapter" data-level="6.3.2" data-path="prediction.html"><a href="prediction.html#controls"><i class="fa fa-check"></i><b>6.3.2</b> Controls</a></li>
<li class="chapter" data-level="6.3.3" data-path="prediction.html"><a href="prediction.html#what-does-overfitting-mean"><i class="fa fa-check"></i><b>6.3.3</b> What does overfitting mean</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="prediction.html"><a href="prediction.html#prediction-vs.explanation"><i class="fa fa-check"></i><b>6.4</b> Prediction vs. Explanation</a></li>
<li class="chapter" data-level="6.5" data-path="prediction.html"><a href="prediction.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>6.5</b> Bias-Variance Tradeoff</a><ul>
<li class="chapter" data-level="6.5.1" data-path="prediction.html"><a href="prediction.html#example-1"><i class="fa fa-check"></i><b>6.5.1</b> Example</a></li>
<li class="chapter" data-level="6.5.2" data-path="prediction.html"><a href="prediction.html#overview"><i class="fa fa-check"></i><b>6.5.2</b> Overview</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="prediction.html"><a href="prediction.html#prediction-policy-problems"><i class="fa fa-check"></i><b>6.6</b> Prediction policy problems</a><ul>
<li class="chapter" data-level="6.6.1" data-path="prediction.html"><a href="prediction.html#references-1"><i class="fa fa-check"></i><b>6.6.1</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>7</b> Cross-Validation</a><ul>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#prerequisites-1"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="7.1" data-path="cross-validation.html"><a href="cross-validation.html#example-predicting-bordeaux-wine"><i class="fa fa-check"></i><b>7.1</b> Example: Predicting Bordeaux Wine</a></li>
<li class="chapter" data-level="7.2" data-path="cross-validation.html"><a href="cross-validation.html#cross-validation-1"><i class="fa fa-check"></i><b>7.2</b> Cross Validation</a></li>
<li class="chapter" data-level="7.3" data-path="cross-validation.html"><a href="cross-validation.html#out-of-sample-error"><i class="fa fa-check"></i><b>7.3</b> Out-of-Sample Error</a><ul>
<li class="chapter" data-level="7.3.1" data-path="cross-validation.html"><a href="cross-validation.html#held-out-data"><i class="fa fa-check"></i><b>7.3.1</b> Held-out data</a></li>
<li class="chapter" data-level="7.3.2" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>7.3.2</b> <span class="math inline">\(k\)</span>-fold Cross-validation</a></li>
<li class="chapter" data-level="7.3.3" data-path="cross-validation.html"><a href="cross-validation.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>7.3.3</b> Leave-one-Out Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cross-validation.html"><a href="cross-validation.html#approximations"><i class="fa fa-check"></i><b>7.4</b> Approximations</a></li>
<li class="chapter" data-level="7.5" data-path="cross-validation.html"><a href="cross-validation.html#references-2"><i class="fa fa-check"></i><b>7.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>8</b> Regularization</a><ul>
<li class="chapter" data-level="8.1" data-path="regularization.html"><a href="regularization.html#ridge-regression"><i class="fa fa-check"></i><b>8.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="8.2" data-path="regularization.html"><a href="regularization.html#regularization-for-causal-inference"><i class="fa fa-check"></i><b>8.2</b> Regularization for Causal Inference</a></li>
<li class="chapter" data-level="8.3" data-path="regularization.html"><a href="regularization.html#references-3"><i class="fa fa-check"></i><b>8.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>9</b> Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression.html"><a href="regression.html#observational-studies"><i class="fa fa-check"></i><b>9.1</b> Observational Studies</a></li>
<li class="chapter" data-level="9.2" data-path="regression.html"><a href="regression.html#regression-and-causality"><i class="fa fa-check"></i><b>9.2</b> Regression and Causality</a></li>
<li class="chapter" data-level="9.3" data-path="regression.html"><a href="regression.html#treatment-effects"><i class="fa fa-check"></i><b>9.3</b> Treatment Effects</a></li>
<li class="chapter" data-level="9.4" data-path="regression.html"><a href="regression.html#ols"><i class="fa fa-check"></i><b>9.4</b> OLS</a></li>
<li class="chapter" data-level="9.5" data-path="regression.html"><a href="regression.html#heterogeneous-effects-and-regression"><i class="fa fa-check"></i><b>9.5</b> Heterogeneous Effects and Regression</a></li>
<li class="chapter" data-level="9.6" data-path="regression.html"><a href="regression.html#balance-and-imbalance"><i class="fa fa-check"></i><b>9.6</b> Balance and Imbalance</a></li>
<li class="chapter" data-level="9.7" data-path="regression.html"><a href="regression.html#key-things"><i class="fa fa-check"></i><b>9.7</b> Key Things</a></li>
<li class="chapter" data-level="9.8" data-path="regression.html"><a href="regression.html#limited-dependent-variables"><i class="fa fa-check"></i><b>9.8</b> Limited Dependent Variables</a></li>
<li class="chapter" data-level="9.9" data-path="regression.html"><a href="regression.html#assessing-selection-on-observables"><i class="fa fa-check"></i><b>9.9</b> Assessing Selection on Observables</a></li>
<li class="chapter" data-level="9.10" data-path="regression.html"><a href="regression.html#omitted-variable-tests"><i class="fa fa-check"></i><b>9.10</b> Omitted Variable Tests</a></li>
<li class="chapter" data-level="9.11" data-path="regression.html"><a href="regression.html#my-advice"><i class="fa fa-check"></i><b>9.11</b> My Advice</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html"><i class="fa fa-check"></i><b>10</b> Panel Data: Fixed Effects and Difference-in-Difference</a><ul>
<li class="chapter" data-level="10.1" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#panel-longitudinal-data"><i class="fa fa-check"></i><b>10.1</b> Panel (Longitudinal) Data</a></li>
<li class="chapter" data-level="10.2" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#terminology"><i class="fa fa-check"></i><b>10.2</b> Terminology</a></li>
<li class="chapter" data-level="10.3" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#fixed-effects"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects</a><ul>
<li class="chapter" data-level="10.3.1" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#estimators"><i class="fa fa-check"></i><b>10.3.1</b> Estimators</a></li>
<li class="chapter" data-level="10.3.2" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#issues-with-fixed-effects"><i class="fa fa-check"></i><b>10.3.2</b> Issues with Fixed Effects</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#difference-in-difference"><i class="fa fa-check"></i><b>10.4</b> Difference-in-Difference</a><ul>
<li class="chapter" data-level="10.4.1" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#basic-differences-in-differences-model"><i class="fa fa-check"></i><b>10.4.1</b> Basic differences-in-differences model</a></li>
<li class="chapter" data-level="10.4.2" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#potential-outcomes-approach-to-did"><i class="fa fa-check"></i><b>10.4.2</b> Potential Outcomes Approach to DiD</a></li>
<li class="chapter" data-level="10.4.3" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#threats-to-identification"><i class="fa fa-check"></i><b>10.4.3</b> Threats to identification</a></li>
<li class="chapter" data-level="10.4.4" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#robustness-checks"><i class="fa fa-check"></i><b>10.4.4</b> Robustness Checks</a></li>
<li class="chapter" data-level="10.4.5" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#extensions"><i class="fa fa-check"></i><b>10.4.5</b> Extensions</a></li>
<li class="chapter" data-level="10.4.6" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#standard-error-issues"><i class="fa fa-check"></i><b>10.4.6</b> Standard Error Issues</a></li>
<li class="chapter" data-level="10.4.7" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#other-did-approaches"><i class="fa fa-check"></i><b>10.4.7</b> Other DiD Approaches</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#lagged-dependent-variables"><i class="fa fa-check"></i><b>10.5</b> Lagged Dependent Variables</a></li>
<li class="chapter" data-level="10.6" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#random-effects"><i class="fa fa-check"></i><b>10.6</b> Random Effects</a><ul>
<li class="chapter" data-level="10.6.1" data-path="panel-data-fixed-effects-and-difference-in-difference.html"><a href="panel-data-fixed-effects-and-difference-in-difference.html#how-to-estimate-random-effects"><i class="fa fa-check"></i><b>10.6.1</b> How to estimate random effects?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html"><i class="fa fa-check"></i><b>11</b> Regression Discontinuity</a><ul>
<li class="chapter" data-level="11.1" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html#examples-1"><i class="fa fa-check"></i><b>11.1</b> Examples</a></li>
<li class="chapter" data-level="11.2" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html#example-close-elections"><i class="fa fa-check"></i><b>11.2</b> Example: Close Elections</a></li>
<li class="chapter" data-level="11.3" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html#software"><i class="fa fa-check"></i><b>11.3</b> Software</a></li>
<li class="chapter" data-level="11.4" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html#references-4"><i class="fa fa-check"></i><b>11.4</b> References</a></li>
</ul></li>
<li class="part"><span><b>IV Presentation</b></span></li>
<li class="chapter" data-level="12" data-path="formatting-tables.html"><a href="formatting-tables.html"><i class="fa fa-check"></i><b>12</b> Formatting Tables</a><ul>
<li class="chapter" data-level="12.1" data-path="formatting-tables.html"><a href="formatting-tables.html#overview-of-packages"><i class="fa fa-check"></i><b>12.1</b> Overview of Packages</a></li>
<li class="chapter" data-level="12.2" data-path="formatting-tables.html"><a href="formatting-tables.html#summary-statistic-table-example"><i class="fa fa-check"></i><b>12.2</b> Summary Statistic Table Example</a></li>
<li class="chapter" data-level="12.3" data-path="formatting-tables.html"><a href="formatting-tables.html#regression-table-example"><i class="fa fa-check"></i><b>12.3</b> Regression Table Example</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="reproducible-research.html"><a href="reproducible-research.html"><i class="fa fa-check"></i><b>13</b> Reproducible Research</a></li>
<li class="chapter" data-level="14" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html"><i class="fa fa-check"></i><b>14</b> Typesetting and Word Processing Programs</a><ul>
<li class="chapter" data-level="14.1" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#latex"><i class="fa fa-check"></i><b>14.1</b> LaTeX</a><ul>
<li class="chapter" data-level="14.1.1" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#learning-latex"><i class="fa fa-check"></i><b>14.1.1</b> Learning LaTeX</a></li>
<li class="chapter" data-level="14.1.2" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#using-latex"><i class="fa fa-check"></i><b>14.1.2</b> Using LaTeX</a></li>
<li class="chapter" data-level="14.1.3" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#latex-with-r"><i class="fa fa-check"></i><b>14.1.3</b> LaTeX with R</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#word"><i class="fa fa-check"></i><b>14.2</b> Word</a><ul>
<li class="chapter" data-level="14.2.1" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#general-advice"><i class="fa fa-check"></i><b>14.2.1</b> General Advice</a></li>
<li class="chapter" data-level="14.2.2" data-path="typesetting-and-word-processing-programs.html"><a href="typesetting-and-word-processing-programs.html#using-r-with-word"><i class="fa fa-check"></i><b>14.2.2</b> Using R with Word</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="writing-resources.html"><a href="writing-resources.html"><i class="fa fa-check"></i><b>15</b> Writing Resources</a><ul>
<li class="chapter" data-level="15.1" data-path="writing-resources.html"><a href="writing-resources.html#writing-and-organizing-papers"><i class="fa fa-check"></i><b>15.1</b> Writing and Organizing Papers</a></li>
<li class="chapter" data-level="15.2" data-path="writing-resources.html"><a href="writing-resources.html#finding-research-ideas"><i class="fa fa-check"></i><b>15.2</b> Finding Research Ideas</a></li>
<li class="chapter" data-level="15.3" data-path="writing-resources.html"><a href="writing-resources.html#replications"><i class="fa fa-check"></i><b>15.3</b> Replications</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="" data-path="references-5.html"><a href="references-5.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\Mat}[1]{\boldsymbol{#1}}
\newcommand{\Vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

\newcommand{\distr}[1]{\mathcal{#1}}
\newcommand{\dnorm}{\distr{N}}
\newcommand{\dmvnorm}[1]{\distr{N}_{#1}}
\newcommand{\dt}[1]{\distr{T}_{#1}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<div id="regression" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Regression</h1>
<p>Two views of regression:</p>
<ol style="list-style-type: decimal">
<li><p>Linear regression is a model of the data generating process:</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;= X \beta + \epsilon \\
\epsilon &amp;\sim \mathsf{Normal}(0, \sigma^2)
\]</span></p>
<ul>
<li>Gauss-Markov assumptions mean BLUE</li>
<li><span class="math inline">\(\hat{beta}\)</span> unbiased <span class="math inline">\(\epsilon\)</span> uncorrelated with <span class="math inline">\(y\)</span>, <span class="math inline">\(\beta\)</span> are unbiased even if assumptions about errors are wrong.</li>
<li>If errors uncorrelated and homoskedastic, if sample size large, the classic standard errors are correct even if errors aren’t normal.</li>
</ul></li>
<li><p>Conditional expectation function</p>
<ul>
<li>OLS is also a model of <span class="math inline">\(E(y| X)\)</span>, which is what we are interested</li>
<li>Even if the functional form is <strong>wrong</strong> (not-linear), OLS produces the best <em>linear approximation to the conditional expectation function (CEF)</em>.</li>
</ul></li>
</ol>
<p>Agnostic justifications for</p>
<ol style="list-style-type: decimal">
<li><p>When is a CEF Linear?</p>
<ol style="list-style-type: decimal">
<li><em>Saturated model</em></li>
<li>Outcome and covariates are <em>multivariate normal</em></li>
</ol></li>
<li><p>OLS produces the best linear predictor (mean squared error) of <span class="math inline">\(y_i\)</span></p></li>
</ol>
<p>Asymptotic OLS Inference</p>
<p><span class="math display">\[
\hat{\beta}_{OLS} = (X&#39;X)X&#39;y \approx E(Y | X)
\]</span></p>
<p>Heteroskedasticity</p>
<p>When will it occur?</p>
<ol style="list-style-type: decimal">
<li>CEF is linear, but <span class="math inline">\(\sigma^(x) = \Var(Y_i | X = x)\)</span> is not linear</li>
<li><span class="math inline">\(E(Y_i | X_i)\)</span> is not linear, but use a linear regression to approximate it.</li>
</ol>
<p>How to estimate the variance covariance matrix of <span class="math inline">\(\beta\)</span>?</p>
<div id="observational-studies" class="section level2">
<h2><span class="header-section-number">9.1</span> Observational Studies</h2>
<p>Identification assumptions</p>
<ol style="list-style-type: decimal">
<li><p>Positivity: All observations can receive the treatment
<span class="math display">\[
0 &lt; \Pr(D_i = 1|X, Y(1), Y(0)) &lt; 1
\]</span></p></li>
<li><p>No unmeasured confounding
<span class="math display">\[
\Pr(D_i = 1 | X, Y(1), Y(0)) = \Pr(D_i = 1 | X)
\]</span>
or
<span class="math display">\[
D_i \perp (Y_i(0), Y_i(1) | X_i
\]</span>
This can be called unconfoundedness, ignorability, selection on observables,
no omitted variables, exogenous, conditional exchangeable.</p></li>
</ol>
</div>
<div id="regression-and-causality" class="section level2">
<h2><span class="header-section-number">9.2</span> Regression and Causality</h2>
<ul>
<li>What does it mean for the <span class="math inline">\(\hat{\beta}\)</span> to be biased?</li>
<li>OVB Doesn’t make sense without a causal question?</li>
<li>Regression is causal if the CEF is causal</li>
<li>When is the CEF is causal?</li>
</ul>
</div>
<div id="treatment-effects" class="section level2">
<h2><span class="header-section-number">9.3</span> Treatment Effects</h2>
<ul>
<li><p>Potential outcomes <span class="math inline">\(Y_i(1)\)</span> and <span class="math inline">\(Y_i(0)\)</span>.</p></li>
<li><p>ATE (Average Treatment Effect)
<span class="math display">\[
\tau = E(Y_i(1) - Y_i(0))
\]</span></p></li>
<li><p>ATT (Average Treatment Effect on the Treated)
<span class="math display">\[
\tau_{ATT} = E(Y_i(1) - Y_i(0) | D_i = 1)
\]</span></p></li>
</ul>
</div>
<div id="ols" class="section level2">
<h2><span class="header-section-number">9.4</span> OLS</h2>
<p>Suppose there is a constant treatment effect, <span class="math inline">\(\tau\)</span>:
<span class="math display">\[
\begin{aligned}
Y_i(0) &amp;= \alpha + X&#39;_i \beta + u_i \\
Y_i(1) &amp;= \alpha + \tau + X&#39;_i \beta + u_i
\end{aligned}
\]</span>
This means that
<span class="math display">\[
Y_i(1) - Y_i(0) = \tau
\]</span>
for all observations.</p>
<p>The usual regression formula is,
<span class="math display">\[
\begin{aligned}[t]
Y_i &amp;= \underbrace{Y_i(1) D_i}_{\text{received treatment} } + \underbrace{Y_i(0) (1 - D_i)}_{\text{didn&#39;t receive treatment}} \\
&amp;= \color{orange}{Y_i(0)} + \color{blue}{(Y_i(1) - Y_i(0)) D_i} \\
&amp;= \color{orange}{\alpha} + \color{blue}{\tau D_i} + \color{orange}{x&#39;_i \beta} + \color{orange}{u_i}
\end{aligned}
\]</span></p>
<p>Remember regression anatomy?</p>
<p>Estimate residuals of regression of the treatment and outcome on the covariates
<span class="math display">\[
\begin{aligned}
\tilde{Y}_i = Y_i - E(Y_i | X_i)  \\
\tilde{D}_i = D_i - E(D_i | X_i)
\end{aligned}
\]</span></p>
<p>Then running a regression of <span class="math inline">\(\tilde{Y}_i\)</span> on <span class="math inline">\(\tilde{D}_i\)</span> is equivalent to controlling for <span class="math inline">\(X_i\)</span>.
<span class="math display">\[
\begin{aligned}
\tilde{Y}_i &amp;= \alpha + \tau D_i + x&#39;_i \beta + u_i \\
\tilde{Y}_i &amp;= \alpha + \tau \tilde{D}_i + \tilde{u}_i
\end{aligned}
\]</span></p>
<p>What does OLS estimate?
<span class="math display">\[
\hat{\tau}_{OLS} = \tau + \frac{\Cov(\tilde{D}_i, \tilde{u}_i)}{\Var(\tilde{D}_i)}
\]</span></p>
<p>The key identification assumption is
<span class="math display">\[
\Cov(\tilde{D}_i, \tilde{u}_i) = 0
\]</span>
I.e. conditional on <span class="math inline">\(X\)</span>, there is no relationship between <span class="math inline">\(D_i\)</span> and <span class="math inline">\(u_i\)</span>.</p>
<p>So <span class="math inline">\(u_i\)</span> is a function of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i(d)\)</span>:</p>
<ul>
<li><span class="math inline">\(u_i = Y_i(0) - \alpha - X&#39;_i \beta\)</span> when <span class="math inline">\(D_i = 0\)</span></li>
<li><span class="math inline">\(u_i = Y_i(1) - \alpha - \tau - X&#39;_i \beta\)</span> when <span class="math inline">\(D_i = 1\)</span></li>
<li>Given <span class="math inline">\(X_i\)</span>, only variation in <span class="math inline">\(u_i\)</span> comes from <span class="math inline">\(Y_i(d)\)</span></li>
</ul>
<p>No unmeasured confounding implies this:
<span class="math display">\[
D_i \perp (Y_i(1), Y_i(0)) | X_i \to D_i \perp u_i | X_i \to \Cov(\tilde{D}_i, \tilde{u}_i) = 0
\]</span></p>
<p>What if it is violated?</p>
<p>Suppose there is an omitted variable <span class="math inline">\(Z_i\)</span> (residualized from <span class="math inline">\(X_i\)</span>),
<span class="math display">\[
\tilde{u}_i = \gamma \tilde{Z}_i + \omega_i
\]</span></p>
<p><span class="math display">\[
\hat{\tau}_{OLS} = \tau + \gamma \frac{\Cov(\tilde{D}_i, \tilde{Z}_i)}{\Var(\tilde{D}_i)}
\]</span></p>
<p>What is the bias in OLS?</p>
<ol style="list-style-type: decimal">
<li>Coefficient of <span class="math inline">\(Z\)</span> on <span class="math inline">\(y\)</span> (<span class="math inline">\(\gamma\)</span>)</li>
<li>Correlation between <span class="math inline">\(\tilde{D}_i\)</span> and <span class="math inline">\(\tilde{Z}_i\)</span></li>
</ol>
</div>
<div id="heterogeneous-effects-and-regression" class="section level2">
<h2><span class="header-section-number">9.5</span> Heterogeneous Effects and Regression</h2>
<p>When does <span class="math inline">\(\tau = \tau_R\)</span>?</p>
<ul>
<li>Constant treatment effects: <span class="math inline">\(\tau(x) = \tau = \tau_{R}\)</span></li>
<li>Constant probability of treatment: <span class="math inline">\(e(x) = P(D_i = 1|X_i = x) = e\)</span></li>
<li>Incorrect model (linearity) in <span class="math inline">\(X\)</span> leads to more bias</li>
</ul>
</div>
<div id="balance-and-imbalance" class="section level2">
<h2><span class="header-section-number">9.6</span> Balance and Imbalance</h2>
<p>See Gelman and Hill (p. 202)</p>
<p>Overlap: the extent to which the range of data is the same across treatment groups</p>
<p>Balance: the extent to which the distribution of data is the same across treatment groups</p>
<p>Imbalance and lack of overlap mean more reliance on the model.</p>
<p>How to evaluate overlap … see below. But plotting the averages of groups for a binary variable (Gelman and Hill, p. 202), or the standardized coefficients of regressions for continuous variables is one way.</p>
<p>Convex hull</p>
<p>King and Zheng: The bias comes from four sources:
<span class="math display">\[
\text{Bias} = \hat{\tau}_{OLS} - \tau = \Delta_o + \Delta_p + \Delta_{e} + \Delta_{i}
\]</span>
where</p>
<ul>
<li><span class="math inline">\(\Delta_o\)</span>: Omitted variable bias</li>
<li><span class="math inline">\(\Delta_p\)</span>: Post-treatment bias</li>
<li><span class="math inline">\(\Delta_e\)</span>: Extrapolation bias—wrong functional form outside the available data</li>
<li><span class="math inline">\(\Delta_i\)</span>: Interpolation bias—wrong functional form inside the available data</li>
</ul>
<p>One way to address this:</p>
<p>The problem: lack of overlap and balance can lead to higher <span class="math inline">\(\Delta_i\)</span> and <span class="math inline">\(\Delta_e\)</span>.</p>
<p>What can we do about it?</p>
<ul>
<li>check for balance and overlap</li>
<li>use matching instead of regression</li>
<li>matching before regression. Sometimes called doubly robust.</li>
</ul>
</div>
<div id="key-things" class="section level2">
<h2><span class="header-section-number">9.7</span> Key Things</h2>
<ol style="list-style-type: decimal">
<li>Agnostic view of regression: CEF and robust standard errors</li>
<li>How to evaluate OVB?</li>
<li>Model dependence</li>
<li>Pre-treatment vs. post-treatment variables</li>
<li>Regression vs. matching</li>
</ol>
</div>
<div id="limited-dependent-variables" class="section level2">
<h2><span class="header-section-number">9.8</span> Limited Dependent Variables</h2>
<ul>
<li><p>Usual advice: use logit/probit for binary, Poisson for counts</p></li>
<li><p>OLS (with robust SE) is correct when:</p>
<ul>
<li>binary treatment and no covariates (difference in means)</li>
<li>binary treatment, discrete covariates, saturated models (stratified diff-in-means)</li>
</ul></li>
<li><p>In unsaturated models, OLS is not bad</p>
<ul>
<li><p>Want estimate of the Average Marginal Effect (<span class="math inline">\(\int_X p(X) E(y | X) dX\)</span>).</p></li>
<li><p>OLS “line” is not a good estimator of any individual marginal effect,
but may be fine for overall AME.</p></li>
<li><p>Logit/probit/Poisson:</p>
<ul>
<li>try to get model of CEF</li>
<li>then calculate AME from estimated CEF</li>
</ul></li>
<li><p>Logit/probit/Poisson impose additional distributional assumptions to
get CEF. Can help if good. Can hurt if wrong. May not be necessary if
only care about AME.</p></li>
<li><p>More common in econ than political science. Many marginally
methodological political scientists will look at using OLS for LDVs
weirdly. Do whatever the reviewer wants even if they are wrong on this
front. The entire point is that OLS vs. these models probably won’t be
that different for AME (but if they are … you probably have to think
very carefully about your model).</p></li>
</ul></li>
</ul>
</div>
<div id="assessing-selection-on-observables" class="section level2">
<h2><span class="header-section-number">9.9</span> Assessing Selection on Observables</h2>
<p>It’s not testable, because it places no restrictions on the observed data.
It requires that the distribution of <span class="math inline">\(Y_i(0)\)</span> is the same for the treatment and non-treatment groups,
<span class="math display">\[
\underbrace{p( Y_i(0) | D_i = 1, X_i )}_{\text{unobserved}} = \underbrace{p(Y_i(0) | D_i = 0, X_i)}_{\text{observed}}
\]</span>
But that requires observing the <em>counterfactual</em>, which isn’t known.</p>
<p>Can use DAGs to use find variables to control for via the <em>backdoor criterion</em>, but the DAG must be correct.</p>
<p>What can we do?</p>
<ol style="list-style-type: decimal">
<li>Placebo tests: Test a different <span class="math inline">\(D_i\)</span> (placebo) that should have no effect.</li>
<li>Balancing tests: Test that the observed covariate distributions are the same for the treated and untreated groups.</li>
<li>Sensitivity/Coefficient stability tests: Test that the treatment effect is insensitive to the addition of new control variables.</li>
<li>Control for as much pre-treatment variables as possible and use principled variable selection methods to optimally trade-off bias and variance.</li>
</ol>
<p>But the general problem is that this assumption is fundamentally untestable.
This is why there is a preference for experiments and methods that try to rely on plausibly exogenous variation in the assignment of <span class="math inline">\(D_i\)</span>:</p>
<ul>
<li>instrumental variables (randomization + exclusion restriction)</li>
<li>over-time-variation (diff-in-diff, fixed effects)</li>
<li>arbitrary thresholds for treatment assignment (RDD)</li>
</ul>
</div>
<div id="omitted-variable-tests" class="section level2">
<h2><span class="header-section-number">9.10</span> Omitted Variable Tests</h2>
<p>The long equation, where we are interested in the estimate of <span class="math inline">\(\beta\)</span>:
<span class="math display">\[
y_i = \alpha + \beta x_i + \gamma z_i + \epsilon
\]</span>
If we estimate
<span class="math display">\[
y_i = \alpha^{(s)} + \beta^{(s)} x_i + \epsilon^{(s)}
\]</span>
the omitted variable bias formula is,
<span class="math display">\[
\beta^{(s)} - \beta = \gamma \delta
\]</span>
where <span class="math inline">\(\delta\)</span> is the coefficient of the <em>balancing equation</em> (regression of <span class="math inline">\(x_i\)</span> on <span class="math inline">\(z_i\)</span>):
<span class="math display">\[
z_i = \delta_0 + \delta x_i + u_i .
\]</span></p>
<p>How to assess omitted variable bias?</p>
<p><strong>Balancing tests:</strong> Test the null hypothesis that <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> are uncorrelated.
<span class="math display">\[
H_0: \delta = 0
\]</span></p>
<p><strong>Coefficient comparison</strong> (sensitivity) test,
<span class="math display">\[
H_0: \beta^{(s)} - \beta = 0
\]</span></p>
<p>Note that the coefficient comparison test is equivalent to
<span class="math display">\[
H_0: \beta^{(s)} - \beta = 0 \leftrightarrow \delta = 0 \text{ or } \gamma = 0
\]</span></p>
<p>How to implement these? More difficult for multiple controls.</p>
<p><em>Balancing test</em>: Regress <span class="math inline">\(z\)</span> on <span class="math inline">\(x\)</span>. Hard with multiple controls. See Sec 5.4.</p>
<p><em>Covariate comparison</em>: Basically the assumption/intuition in these tests is that going from no-controls to observed controls gives the researcher some insight into how problematic unobserved controls could be.</p>
<ul>
<li><p>Informally compare coefficients. Add variables and see if <span class="math inline">\(\hat{\beta}\)</span> changes substantively.</p></li>
<li><p>Hausmann test and Chow tests proposed in Hausmann. Pischke and Pei.</p></li>
<li><p>Altonji, Elder, and Taber (2005) propose and Nunn and Wantchekon (2011)
use a slightly different method assess potential bias. Let <span class="math inline">\(\hat{\beta}\)</span> be
the OLS estimate of <span class="math inline">\(\beta\)</span> from the full regression (all covariates),
and <span class="math inline">\(\hat{\beta}^{(s)}\)</span> be the OLS estimate from a regression with no
(or few) controls. Calculate
<span class="math display">\[
B = \frac{\hat{\beta}}{\hat{\beta}^{(s)} - \hat{\beta}} .
\]</span>
The smaller <span class="math inline">\(\hat{\beta}^{(s)} - \hat{\beta}\)</span>, the less the regression is selected by selection on observables.
This should be greater than one. The interpretation of <span class="math inline">\(B\)</span> is that it is the multiplier that unobserved covariates would have to have in order to make the estimated effect equal to zero.</p></li>
</ul>
<p>This coefficient stability argument makes some sense. If we think of observed covariates as a sample from the population of possible covariates, they provide information about the distribution of other unobserved covariates. But this sample isn’t random, and that can have perverse incentives:</p>
<ul>
<li><p>If the researcher does a good job controlling for confounders, then the
effect of future confounders may appear large.</p></li>
<li><p>If the researcher does a poor job controlling for confounders, then the
effect of future confounders will appear minimal.</p></li>
<li><p>This depends on a pre-existing “good” model, but there’s no way to assess
that. Oster (2016) adjusts this method to account for the <span class="math inline">\(R^2\)</span> of the
regression. If it explains a lot, there is less for omitted variables to
do. However, the solution is complicated.</p></li>
</ul>
</div>
<div id="my-advice" class="section level2">
<h2><span class="header-section-number">9.11</span> My Advice</h2>
<ul>
<li><p>Focus on one variable at a time (no all causes regression)</p></li>
<li><p>Control for as many pre-treatment covariates as you can</p></li>
<li><p>Check that you aren’t controlling for post-treatment variables</p></li>
<li><p>If you are only interested in the AME of the treatment, you can include
it as a linear term.</p></li>
<li><p>It is more important to be flexible as the controls (while trading off
bias and variance). You shouldn’t worry about discretizing continuous
controls. It isn’t <em>wrong</em> because they are continuous. It may or may not
be useful for improving balance.</p></li>
<li><p>Formally or informally check the balance and overlap of your regression.</p></li>
<li><p>Use regression anatomy to understand how many effective number of
observations you have … which observations have the most variation in
the treatment after conditioning on the controls. These are the cases which
are providing all the information about your inferences.</p></li>
<li><p>Use either a principled model selection method with regularization, and/or the OVB tests</p></li>
<li><p>Use a placebo test if possible</p></li>
<li><p>Use heteroskedasticity consistent (robust) standard errors; possible with autocorrelation or clustering adjustment.</p></li>
<li><p>Take the OLS model “seriously but not literally”.
It is an approximation of the CEF, and under some
assumptions it is a type of weighted average treatment effect.
It does not “assume” or “require” that the effect is linear or homogeneous
(though it works better in those situations).</p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regularization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="panel-data-fixed-effects-and-difference-in-difference.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jrnold/intro-method-notes/edit/master/causal-regression.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
