---
title: "Weighted Regression"
---

# Weighting in Regression

Suppose that the heteroskedasticity is known up to a multiplicative constant,
$$
\Var(\varepsilon_i | \mat{X}) = a_i \sigma^2 ,
$$
where $a_i = a_i \vec{x}_i'$ is a positive and known function of $\vec{x}_i$.

Then in weighted least squares multiply $y_i$ by $1 / \sqrt{a_i}$,
$$
\begin{aligned}[t]
y_i &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_K x_K + \varepsilon_i \\
y_i / \sqrt{a_i} &= \beta_0 / \sqrt{a_i} + \beta_1 x_1 / \sqrt{a_1} + \beta_2 x_2 / \sqrt{a_2} + \dots + \beta_K x_K / \sqrt{a_K} + \varepsilon_i^*
\end{aligned}
$$
where $\varepsilon_i^* \sim N(0, \sigma^2)$.
This rescales errors to $\varepsilon_i / \sqrt{a_i}$ which keeps $\E(\varepsilon_i) = 0$, but makes the variance constant,
$$
\Var\left( \frac{1}{\sqrt{a_i}} \varepsilon_i | \mat{X} \right) = \frac{1}{a_i} \Var(\varepsilon_i | \mat{X}) = \frac{1}{a_i} a_i \sigma^2 = \sigma^2
$$
If $a_i$ is known, then the model is homoskedastic and the estimator is BLUE.

Define the weighting matrix,
$$
\mat{W} =
\begin{bmatrix}
1 / \sqrt{a_1} & 0 & \cdots & 0 \\
0 & 1 / \sqrt{a_2} & \cdots & 0 \\
\vdots & \vdots & \ddots & 0 \\
0 & 0 & \cdots & 1 / \sqrt{a_N}
\end{bmatrix} .
$$
Then run the regression,
$$
\begin{aligned}[t]
\mat{W} y &= \mat{W} \mat{X} \vec{\beta} + \mat{W} \vec\varepsilon \\
\vec{y}^* &= \mat{X}^* \vec{\beta} + \vec{\varepsilon}^* .
\end{aligned}
$$
Run the regression of $\vec{y}^*$ on $\mat{X}^*$, and the Gauss-Markov assumptions are satisfied.
Then using the usual OLS formula,
$$
\hat{\vec\beta}_{WLS} = ((\mat{X}^*)' \mat{X}^*) (\mat{X}^*)' \vec{y}^* = (\mat{X}' \mat{W}' \mat{W} \mat{X})^{-1} \mat{X}' \mat{W}' \mat{W} \vec{y} .
$$

**In R** Use `lm()` with the `weights` argument.

TODO: when is WLS useful

See MHE on "weighting",



## References

- WLS derivation @Fox2016a 304--306

Textbook discussions: @AngristPischke2009 91--94, @AngristPischke2014 202--203, 

@SolonHaiderWooldridge2015a is a good (and recent) overview with practical advice of when to weight and when not-to weight linear regressions.

@Gelman2007a, in the context of post-stratification, proposes controlling for variables related to selection into the sample instead of using survey weights; also see the responses [@BellCohen2007a; @BreidtOpsomer2007a; @Little2007a; @Pfeffermann2007a], and rejoinder [@Gelman2007b] and [blog post](http://andrewgelman.com/2015/07/14/survey-weighting-and-regression-modeling/).
Gelman's approach is similar to that earlier suggested by @WinshipRadbill1994a.

See also @Deaton1997a, @DumouchelDuncan1983a, and @WissokerYYYYa.

For survey weighting, see the R package [survey](https://cran.r-project.org/web/packages/survey/survey.pdf) and its 
