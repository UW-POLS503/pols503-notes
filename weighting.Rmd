---
title: "Weighted Regression"
---

# Weighting in Regression

Suppose that the heteroskedasticity is known up to a multiplicative constant,
$$
\Var(\varepsilon_i | \mat{X}) = a_i \sigma^2 ,
$$
where $a_i = a_i \vec{x}_i'$ is a positive and known function of $\vec{x}_i$.

Then in weighted least squares multiply $y_i$ by $1 / \sqrt{a_i}$,
$$
\begin{aligned}[t]
y_i &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_K x_K + \varepsilon_i \\
y_i / \sqrt{a_i} &= \beta_0 / \sqrt{a_i} + \beta_1 x_1 / \sqrt{a_1} + \beta_2 x_2 / \sqrt{a_2} + \dots + \beta_K x_K / \sqrt{a_K} + \varepsilon_i^*
\end{aligned}
$$
where $\varepsilon_i^* \sim N(0, \sigma^2)$.
This rescales errors to $\varepsilon_i / \sqrt{a_i}$ which keeps $\E(\varepsilon_i) = 0$, but makes the variance constant,
$$
\Var\left( \frac{1}{\sqrt{a_i}} \varepsilon_i | \mat{X} \right) = \frac{1}{a_i} \Var(\varepsilon_i | \mat{X}) = \frac{1}{a_i} a_i \sigma^2 = \sigma^2
$$
If $a_i$ is known, then the model is homoskedastic and the estimator is BLUE.

Define the weighting matrix,
$$
\mat{W} =
\begin{bmatrix}
1 / \sqrt{a_1} & 0 & \cdots & 0 \\
0 & 1 / \sqrt{a_2} & \cdots & 0 \\
\vdots & \vdots & \ddots & 0 \\
0 & 0 & \cdots & 1 / \sqrt{a_N}
\end{bmatrix} .
$$
Then run the regression,
$$
\begin{aligned}[t]
\mat{W} y &= \mat{W} \mat{X} \vec{\beta} + \mat{W} \vec\varepsilon \\
\vec{y}^* &= \mat{X}^* \vec{\beta} + \vec{\varepsilon}^* .
\end{aligned}
$$
Run the regression of $\vec{y}^*$ on $\mat{X}^*$, and the Gauss-Markov assumptions are satisfied.
Then using the usual OLS formula,
$$
\hat{\vec\beta}_{WLS} = ((\mat{X}^*)' \mat{X}^*) (\mat{X}^*)' \vec{y}^* = (\mat{X}' \mat{W}' \mat{W} \mat{X})^{-1} \mat{X}' \mat{W}' \mat{W} \vec{y} .
$$

**In R** Use `lm()` with the `weights` argument.

## Sampling Weights

Using sampling weights is most important for univariate statistics which are estimates of population parameters. 
However, whether to use them when estimating a regression is less clear.

- if sample weights are a function of $X$ only, estimates are unbiased and more efficient without weighting
- if the sample weights are a function of $Y | X$, then use the weights

With fixed $X$, regression does not require random sampling, so the sampling weights of the 
$X$ are irrelevants.

If the original unweighted data are homoskedastic, then sampling weights induces heteroskedasticity.
Suppose the true model is,
$$
Y_i = \vec{x}\T \vec{\beta} + \varepsilon_i
$$
where $\varepsilon_i \sim N(0, \sigma^2)$.
Then the weighted model is,
$$
\sqrt{w_i} Y_i = \sqrt{w_i} \vec{x}\T \vec{\beta} + \sqrt{w_i} \varepsilon_i
$$
and now $\sqrt{w_i} \varepsilon_i \sim N(0, w_i \sigma^2)$.

If the sampling weights are only a function of the $X$, then controlling for $X$ is sufficient.
In fact, OLS is preferred to WLS, and will produce unbiased and efficient estimates.
The choice between OLS and WLS is a choice between different distributions of $\mat{X}$.
However, if the model is specified correctly the coefficients should be the same, regardless
of the distribution of $\mat{X}$.
Thus, if the estimates of OLS and WLS differ, then it is evidence that the model is misspecified.

@WinshipRadbill1994a suggest using the method of @DumouchelDuncan1983a to test whether the OLS and WLS are difference.

1. Estimate $E(Y) = \mat{X} \beta$
2. Estimate $E(Y) = \mat{X} \beta + \delta \vec{w} + \vec{\gamma} \vec{w} \mat{X}$,
    where all $X$
3. Test regression 1 vs. regression 2 using an F test.
4. If the F-test is significant, then the weights are not simply a function of $X$. Either try to respecify the model or use WLS with robust standard errors. 
    If the F-test is insignificant, then the weights are simply a function of $X$. Use OLS.

Modern survey often use complex multi-stage sampling designs.
Like clustering generally, this will affect the standard errors of these regressions.
Clustering by primary sampling units is a good approximation of the standard errors from multistage sampling.


## References

- WLS derivation @Fox2016a 304--306

Textbook discussions: @AngristPischke2009 91--94, @AngristPischke2014 202--203, 

@SolonHaiderWooldridge2015a is a good (and recent) overview with practical advice of when to weight and when not-to weight linear regressions. Also see the advice from the [World Bank blog](http://blogs.worldbank.org/impactevaluations/tools-of-the-trade-when-to-use-those-sample-weights).

@Gelman2007a, in the context of post-stratification, proposes controlling for variables related to selection into the sample instead of using survey weights; also see the responses [@BellCohen2007a; @BreidtOpsomer2007a; @Little2007a; @Pfeffermann2007a], and rejoinder [@Gelman2007b] and [blog post](http://andrewgelman.com/2015/07/14/survey-weighting-and-regression-modeling/).
Gelman's approach is similar to that earlier suggested by @WinshipRadbill1994a.


See also @Deaton1997a, @DumouchelDuncan1983a, and @WissokerYYYYa.

For survey weighting, see the R package [survey](https://cran.r-project.org/web/packages/survey/survey.pdf) and its 
